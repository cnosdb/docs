<!doctype html>
<html lang="en-US" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-reference/design">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.3.1">
<title data-rh="true">Design | CnosDB</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://cnosdb.com/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://cnosdb.com/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://cnosdb.com/docs/reference/design"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Design | CnosDB"><meta data-rh="true" name="description" content="Concepts"><meta data-rh="true" property="og:description" content="Concepts"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://cnosdb.com/docs/reference/design"><link data-rh="true" rel="alternate" href="https://cnosdb.com/docs/reference/design" hreflang="en-US"><link data-rh="true" rel="alternate" href="https://cnosdb.com/zh-Hans/docs/reference/design" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://cnosdb.com/docs/reference/design" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="CnosDB RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="CnosDB Atom Feed"><link rel="stylesheet" href="/assets/css/styles.13aca0f8.css">
<link rel="preload" href="/assets/js/runtime~main.093b838e.js" as="script">
<link rel="preload" href="/assets/js/main.3280fb8b.js" as="script">
</head>
<body class="navigation-with-keyboard" data-theme="light">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">CnosDB</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Tutorial</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><div class="searchBox_ZlJk"><div class="dsla-search-wrapper"><div class="dsla-search-field" data-tags="default,docs-default-current"></div></div></div><a class="navbar__item navbar__link" href="/path">Version</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/docs/reference/design" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en-US">English</a></li><li><a href="/zh-Hans/docs/reference/design" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-Hans">简体中文</a></li><li><a href="https://github.com/cnosdb/docs" target="_blank" rel="noopener noreferrer" class="dropdown__link">帮助我们翻译</a></li></ul></div><a href="https://github.com/cnosdb/cnosdb" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Home</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/get-started">Get Started</a><button aria-label="Toggle the collapsible sidebar category &#x27;Get Started&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/develop">Develop</a><button aria-label="Toggle the collapsible sidebar category &#x27;Develop&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/deploy">Deploy</a><button aria-label="Toggle the collapsible sidebar category &#x27;Deploy&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/manage">Manage</a><button aria-label="Toggle the collapsible sidebar category &#x27;Manage&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/docs/category/reference">Reference</a><button aria-label="Toggle the collapsible sidebar category &#x27;Reference&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/reference/design">Design</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/reference/rest_api">REST API</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/reference/connector">Connector</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/reference/sql">SQL Reference</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/reference/tools">CnosDB Tools</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/reference/config">Configuration</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/reference/ecosystem">Eco-integration</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/reference/performance">Benchmark</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/manage-1">Manage</a><button aria-label="Toggle the collapsible sidebar category &#x27;Manage&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/reference"><span itemprop="name">Reference</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Design</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Design</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="concepts">Concepts<a href="#concepts" class="hash-link" aria-label="Direct link to Concepts" title="Direct link to Concepts">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="background">Background<a href="#background" class="hash-link" aria-label="Direct link to Background" title="Direct link to Background">​</a></h3><p>The twenty-first century we are living in is an era of explosive growth of data information, in which all kinds of data information are expanding, individuals and enterprises are aware of the importance of data information, and with the advent of big data era, we have new challenges and requirements for insight into this data information. Based on the above-mentioned background of massive data, the database field has segmented some data information in specific formats to obtain better storage and retrieval performance.
Our time series data is one of the branches born in this context. This article focuses on the time series database users to carry out a basic concept of pulling together, in order to help us better navigate the time series data.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="time-series">Time Series<a href="#time-series" class="hash-link" aria-label="Direct link to Time Series" title="Direct link to Time Series">​</a></h3><p>In the ocean, we may monitor a variety of data indicators, used to study the environment, weather and human production, for example, a scenario: Suppose we have a detector that can record the visibility of the ocean air, we can determine whether to produce based on visibility changes. This visibility information is a time series data, in a common sense is a line graph of changes over time.</p><p><img loading="lazy" alt="Time Series" src="/assets/images/air_vis-82d2e9dbe0a84bdd52e21e298b873222.png" width="757" height="450" class="img_ev3q"></p><p>So let&#x27;s make a summary:</p><p>Time Series is a line with time on the x-axis and a state index on the y-axis, which is used to describe the state of things over a period of time.</p><p>CnosDB is a time series database, whose application is to store data related to time series, providing efficient writing and querying.
Therefore, CnosDB has designed the design model of time series based on the characteristics of time series data.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="data-model">Data Model<a href="#data-model" class="hash-link" aria-label="Direct link to Data Model" title="Direct link to Data Model">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="timestamp">TimeStamp<a href="#timestamp" class="hash-link" aria-label="Direct link to TimeStamp" title="Direct link to TimeStamp">​</a></h4><p>A time series database requires that each piece of data written be time-stamped, indicating the moment when the data was collected.</p><p>CnosDB supports setting the precision of the time.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="tag">Tag<a href="#tag" class="hash-link" aria-label="Direct link to Tag" title="Direct link to Tag">​</a></h4><p>In the application scenario of temporal database, there are some data that do not change with time, such as the location of the IoT collection device, the name of the device, and the owner of the device.</p><p>This data is called<strong>Tag</strong>and we use STRING to store Tag.</p><p>In CnosDB a tag data is a key-value pair, consisting of Key and Value, Key is the tag name and Value is the tag value.</p><p>Usually, for better classification, multiple Tag pairs are used to tag a time series, i.e. Tags.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="field">Field<a href="#field" class="hash-link" aria-label="Direct link to Field" title="Direct link to Field">​</a></h4><p>In a time-series database application scenario, some data changes over time, such as the data collected by IoT collection devices.</p><p>For a device that detects the environment, it collects information such as room temperature, humidity, etc., which changes over time, and these data we call <strong>Field</strong>.</p><p>The collected data is diverse, CnosDB provides <code>BIGINT</code>,<code>BIGINT UNSIGNED</code>,<code>DOUBLE</code>,<code>STRING</code>,<code>BOOLEAN</code> for storing fields, and also provides compression algorithm to store them efficiently.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="row">Row<a href="#row" class="hash-link" aria-label="Direct link to Row" title="Direct link to Row">​</a></h4><p>A timestamp, a set of tags, and a set of fields make up a row of data, which many people also call a point.</p><p>A data row must contain a timestamp, at least one tag, and at least one field.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="table">Table<a href="#table" class="hash-link" aria-label="Direct link to Table" title="Direct link to Table">​</a></h4><p>A Table is an organization of rows of data with the same label and fields. This is very similar to the concept of a table in a relational database.</p><p>Timestamps, labels, and fields are equivalent to columns of tables in a relational database.</p><p>The only difference is that the rows in CnosDB are rows of data consisting of timestamps, labels, and fields.</p><p>We can use our familiar SQL to manipulate the tables in CnosDB database that store time series data. INSERT and most SELECT statements in SQL standard are efficiently supported by CnosDB.</p><p><strong>Example</strong></p><p>The following is a table storing data</p><table><thead><tr><th>Timestamp</th><th>NodeID</th><th>CPU</th><th>Memory</th></tr></thead><tbody><tr><td>time1</td><td>node1</td><td>15%</td><td>35%</td></tr><tr><td>time2</td><td>node2</td><td>23%</td><td>45%</td></tr><tr><td>time3</td><td>node1</td><td>19%</td><td>50%</td></tr><tr><td>time4</td><td>node2</td><td>80%</td><td>70%</td></tr></tbody></table><p>Where the Timestamp column is the timestamp, the NodeID column is the label, and CPU and Memory are the fields</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="database">DataBase<a href="#database" class="hash-link" aria-label="Direct link to DataBase" title="Direct link to DataBase">​</a></h4><p>A database is made up of multiple tables, which is similar to a relational database. Each table stores data of different structure.</p><p>Users can use SQL to manipulate different tables in the database and also perform join queries of tables.</p><p>CnosDB supports setting different storage policies for a database, data retention time, number of data slices, slice setting policy, time precision, etc.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="architecture">Architecture<a href="#architecture" class="hash-link" aria-label="Direct link to Architecture" title="Direct link to Architecture">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="design-objectives">Design Objectives<a href="#design-objectives" class="hash-link" aria-label="Direct link to Design Objectives" title="Direct link to Design Objectives">​</a></h3><p>Consdb2.0 is developed in Rust language, based on its security, high performance and community influence, provides users with an excellent time series database and forms a complete DBaas solution.</p><blockquote><p><strong>Time Series Database</strong></p><ol><li>Extensive: Theoretically supported time series has no limit, completely solves the problem of time series expansion, and supports cross-river expansion.</li><li>Calculate storage separation: Calculating nodes and storage nodes, can expand and shrink capacity independently and on a second scale.</li><li>Storage performance and cost: High performance io stacks support hierarchical storage using cloud discs and object storage.</li><li>The query engine supports vector queries.</li><li>Supports multiple time series protocols to write and query, providing external component import data.</li></ol></blockquote><blockquote><p><strong>Original Cloud</strong></p><ol><li>Support cloud native, support the full use of cloud infrastructure to integrate into cloud native ecology.</li><li>High availability, second-level failure recovery, support multi-cloud, cross-regional disaster preparedness.</li><li>Native support multi-tenant, pay on schedule.</li><li>The CDC log provides subscriptions and distributions to other nodes.</li><li>Provide users with more configuration items to meet multiple-scenario complex requirements for public cloud users.</li><li>Cloud side synergizes to provide the ability to fuse side ends with public clouds.</li><li>Blend the OLAP / CloudA data ecosystem on the cloud.</li></ol></blockquote><p>In the process of redesigning the time series database, we solve a series of problems faced by the current time series database  as much as possible, form a complete set of time series data solutions and  time series  ecosystem and provide DBaas services in public clouds.</p><p><img loading="lazy" alt="整体架构" src="/assets/images/new_arch-78c462b6a4667816d43e32b53ec63e39.jpg" width="1615" height="802" class="img_ev3q"></p><blockquote><p>We will have the elaboration from following aspects.</p></blockquote><ul><li>Data replication and consensus</li><li>Meta cluster</li><li>SQL engine</li><li>tskv index and data storage</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="data-replication-and-consensus">Data Replication and Consensus<a href="#data-replication-and-consensus" class="hash-link" aria-label="Direct link to Data Replication and Consensus" title="Direct link to Data Replication and Consensus">​</a></h3><p>The fragment rule of CnosDB 2.0 is based on Time-range. It uses the fragmentation rule of DB + Time_range to place the data in the corresponding Bucket. Bucket is a virtual logic unit. Each Bucket consists of the following main properties. Bucket creates multiple fragments based on user configurations, dissipating data (suppose data fragment Shad Num is 1).&gt; 「db， shardid， time_range， create_time， end_time， List\&lt;Vnode<!-- -->&gt;<!-- -->」</p><p>Vnode is a virtual running unit and is distributed to a specific Node. Each Vnode is a separate LSM Tree. Its corresponding tsfamily structure is a separate running unit.</p><p><img loading="lazy" alt="数据分片" src="/assets/images/buket-ed2b08d678cb21fefce319574467e994.jpg" width="1859" height="1585" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="replicaset">Replicaset<a href="#replicaset" class="hash-link" aria-label="Direct link to Replicaset" title="Direct link to Replicaset">​</a></h4><p>The high availability of data can be maintained through data replica set. Each db has its own replica group representing the number of data redundants. A set of Vnotes within the same bucket forms a replica group with the same data and inverted index information.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="place-rule">Place Rule<a href="#place-rule" class="hash-link" aria-label="Direct link to Place Rule" title="Direct link to Place Rule">​</a></h4><p>To address the possibility of concurrent failures, the meta node may need to ensure that data copies are located on devices that use different nodes, racks, power sources, controllers and physical locations, when creating bucket. Considering that different tenants will access data at different region, Vnote should be dispatched and discharged by the way of optimal cost.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="data-separation-strategy">Data Separation Strategy<a href="#data-separation-strategy" class="hash-link" aria-label="Direct link to Data Separation Strategy" title="Direct link to Data Separation Strategy">​</a></h4><p>Data from different tenants on Node are physically segmented.</p><p><code>/User/db/bucket/replicaset_id/vnode_id</code></p><p><img loading="lazy" alt="数据分割目录存储" src="/assets/images/data_path-c4ecef6df78e03b5ace428a7c13af089.jpg" width="1680" height="842" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="data-consensus-based-on-quorum-mechanism">Data Consensus Based on Quorum Mechanism<a href="#data-consensus-based-on-quorum-mechanism" class="hash-link" aria-label="Direct link to Data Consensus Based on Quorum Mechanism" title="Direct link to Data Consensus Based on Quorum Mechanism">​</a></h4><ul><li><h4 class="anchor anchorWithStickyNavbar_LWe7" id="the-cnosdb20-is-implemented-as-a-system-with-final-consistency">The Cnosdb2.0 is implemented as a system with final consistency.<a href="#the-cnosdb20-is-implemented-as-a-system-with-final-consistency" class="hash-link" aria-label="Direct link to The Cnosdb2.0 is implemented as a system with final consistency." title="Direct link to The Cnosdb2.0 is implemented as a system with final consistency.">​</a></h4><p>  The module using the Quorum mechanism to make data consensuss and handling read or write requests is called codenatoor.</p><ul><li><p>Meta information cache, interact with meta nodes</p><p>  According to user, db, Timemange, get Vnote information, maintain a cache locally and pull VodeList from the remote without a local hit. Provide a trait of Meta Client.</p></li><li><p>Connection management</p><p>Manages connections with different tskvs for data reading/writing.</p></li><li><p>Agent operation for data reading/writing/deleting</p><p>Data is configured by users to support a variety of different consistency levels.</p><div class="language-Rust codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-Rust codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pub enum ConsistencyLevel {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    /// allows for hinted handoff， potentially no write happened yet.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Any，</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    /// at least one data node acknowledged a write/read.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    One，</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    /// a quorum of data nodes to acknowledge a write/read.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Quorum，</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    /// requires all data nodes to acknowledge a write/read.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    All，</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></li><li><p>Hinted handoff<br>
<!-- -->Add under the scenario of a temporary failure of the target node to provide the Hinted handoff function of the continator node, which is persistently saved in the Hinted handoff queue of the node, until the copy node fails and then copied and recovered from the Hinted handoff queue.</p><p>Data are written</p><p>When a write request is received, the cordinator determines the physical node (note) where the data to be stored, based on the partition policy and the corresponding placement rules (place-rule). As long as at least W nodes return to success, the writing operation is considered successful.</p></li></ul></li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="writer-process">Writer Process<a href="#writer-process" class="hash-link" aria-label="Direct link to Writer Process" title="Direct link to Writer Process">​</a></h4><p><img loading="lazy" alt="write" src="/assets/images/write-a61a973b0dc5621f852d3f7fc67e77ea.jpg" width="2320" height="1669" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="data-reading">Data Reading<a href="#data-reading" class="hash-link" aria-label="Direct link to Data Reading" title="Direct link to Data Reading">​</a></h4><p>When a read request is received, the cordinator determines that the physical node (note) where the data to be stored and requires this key corresponding data based on the partition policy and the corresponding placement rules (place-rule), and at present we do not perform the function of read repair (read repair) to initiate only one reading request. In the case of delay in reading, initiate a second reading request.</p><p><img loading="lazy" alt="read" src="/assets/images/read-1d0000a2e90e18b0a90d6ae3dfb5b391.jpg" width="2170" height="1699" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="update-of-conflicts">Update of Conflicts<a href="#update-of-conflicts" class="hash-link" aria-label="Direct link to Update of Conflicts" title="Direct link to Update of Conflicts">​</a></h4><ol><li>After data creates conflict in a time series scenario, use consistency hash to be replaced by the first copy (replaica) as a confirmation point</li><li>At the same time, the last-write-win strategy is used to resolve conflicts.</li></ol><h3 class="anchor anchorWithStickyNavbar_LWe7" id="meta-cluster">Meta Cluster<a href="#meta-cluster" class="hash-link" aria-label="Direct link to Meta Cluster" title="Direct link to Meta Cluster">​</a></h3><p>Maintain a strong consistency meta cluster through raft. Meta cluster api serves externally, while nodes also subscribe to updates to meta information. All metadata updates are updated through the meta-data cluster.</p><p><img loading="lazy" alt="meta——server" src="/assets/images/raft-d9e79220e4df457daf5a1a88cc7afd89.jpg" width="1339" height="1114" class="img_ev3q"></p><blockquote><ol><li>Database catalog information, DDL operation.</li><li>The node probe/node registration, as well as node load information statistics, is the basis for the read and write selected by coordinator.</li><li>Rent and sub-user information and permissions are relevant.</li><li>Data routing information, the routing information corresponding to vnodeList corresponding to denant / db / bucket / replicaset.</li><li>Provides the functionality of distributed locks and watch change notifications.</li></ol></blockquote><p>We adopt a strong consistency meta cluster and realize corresponding optimization. The specific reasons are as follows:</p><blockquote><ul><li>In practice, metadata in our cluster is usually controlled on a smaller scale and without extensible requirements.</li><li>Engineering practice is relatively simple and is conducive to rapid iteration.</li><li>Make cache and localized storage for access to frequently accessible data, optimize.<ul><li>After storage locally, subscribe to schema version changes from the meta cluster to relieve the pressure of meta cluster reading.</li><li>Meta clusters share the leveler pressure and provide the Follower / Read scheme. Reading performance is optimized.</li></ul></li></ul></blockquote><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sql-engine">SQL Engine<a href="#sql-engine" class="hash-link" aria-label="Direct link to SQL Engine" title="Direct link to SQL Engine">​</a></h3><p>We used <a href="https://arrow.apache.org/datafusion/" target="_blank" rel="noopener noreferrer">DataFusion</a> as the query engine. DataFusion is an extensible query execution framework, written with Rust, used <a href="https://arrow.apache.org/" target="_blank" rel="noopener noreferrer">Apache Arrow</a> As its memory format. DataFusion supports SQL and DataFrame API for building logical query schemes, as well as query optimizers and execution engines that can be executed in parallel with partition data sources using threads. It has the following advantages:</p><ol><li>High performance: Using the memory models of Rust and Arrow, it has high performance.</li><li>Strong extensibility: Allows almost any point in its design to be extended and customized with a needle-specific use case.</li><li>High quality: DataFusion and Arrow ecology are widely tested and can be used as production systems.</li><li>Fusion of large data ecology: As part of the Apache Arrow ecosystem (Arrow, Flight, Parquet), it is better integrated with large data ecosystems.</li></ol><p>By extending DataFusion data sources and providing custom SQL statements, the query process for data under distributed scenarios is as follows:</p><p><img loading="lazy" alt="query" src="/assets/images/query_data_path-2e36ba1dd32dbee181bad6834abf2429.jpg" width="3079" height="2524" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="tskv-index-and-data-storage">TSKV Index and Data Storage<a href="#tskv-index-and-data-storage" class="hash-link" aria-label="Direct link to TSKV Index and Data Storage" title="Direct link to TSKV Index and Data Storage">​</a></h3><p>tskv mainly undertakes data and index storage, manages all Vnodes on node, each Vnode is responsible for some of the data in a db. In Vnode, three modules mainly make up WAL, Index Engine and Data Engine.</p><p><img loading="lazy" alt="tskv" src="/assets/images/tskv-591083e460ae6d574a2a0a89aee00cb0.jpg" width="844" height="487" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="index-engine">Index Engine<a href="#index-engine" class="hash-link" aria-label="Direct link to Index Engine" title="Direct link to Index Engine">​</a></h4><p>Indexes used to store time series data are usually models that read more and write less, mainly quickly indexing and tagkey-based conditional filtering to filter out the right series.</p><p>The main functions are:</p><ol><li>Storage positive index</li><li>Storage reverse index</li><li>Caching catalog information</li></ol><p>Common query statements：</p><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">SELECT</span><span class="token plain"> xxx </span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">table</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">where</span><span class="token plain"> tag1</span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> value1 </span><span class="token operator" style="color:#393A34">&amp;&amp;</span><span class="token plain"> tag2</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">value2 </span><span class="token punctuation" style="color:#393A34">[</span><span class="token operator" style="color:#393A34">and</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">time</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> aaa </span><span class="token operator" style="color:#393A34">and</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">time</span><span class="token plain">  \</span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain"> bbb</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token keyword" style="color:#00009f">group</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">by</span><span class="token plain">\</span><span class="token keyword" style="color:#00009f">order</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">by</span><span class="token plain">\</span><span class="token keyword" style="color:#00009f">limit</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The design of index is mainly aimed at the where filtering conditions; used to reduce the search scale of data and speed up the query efficiency of data.</p><p>Support the following filtering conditions:</p><blockquote><ol><li>Equal to; not equal to; such as: tag = value, tag! = Value</li><li>More than; less than; such as: tag  \&lt; value</li><li>Prefix matching; such as: tag = aaa_*</li><li>Regular expressions; such as: tag = aaa*bbb</li></ol></blockquote><p>Indexes is built when the data is written. In time series database, each tag is indexed, and the corresponding value of multiple tags is combined into a searchkey. Although time series databases are writing more and reading less, the use of indexes when writing data is more read than build. Time series databases are often written to different time points of the same search, so each search<!-- -->&#x27;<!-- -->s index information needs to be built only when it is first written, and if the search exists (reading operation), no longer indexed;</p><ul><li><h4 class="anchor anchorWithStickyNavbar_LWe7" id="storage-structure">Storage structure<a href="#storage-structure" class="hash-link" aria-label="Direct link to Storage structure" title="Direct link to Storage structure">​</a></h4><ul><li><p>Based on the hash function, calculate HashID: <code>hash (SeriesKey) -&gt; HashID</code> (24-bit integer, about 16 million); 2.HashID (uint64): <code>HashID  \&lt; 40 | auto_increment_id -&gt; SeresID</code> is obtained.</p><ul><li>FieldID (uint64) is combined by SeriesID with TableFiledID (field has a number within the table for TableFiledID)：</li></ul><p>Conditions of limitation: </p><ul><li>The number of HashIDs is about 16 million, and hundreds of millions of single machine Series will lead to List lengthening drag-and-seeking.</li><li>The 24th bits of FieldID are TableFiledID, and the lower 40 bits are the lower 40 bits of SeresID.</li></ul></li></ul><p>The TSM data file stores FieldID and corresponding Data information. The information about SeresKey is stored in the index file, and the following is about the index data organization.</p></li><li><h4 class="anchor anchorWithStickyNavbar_LWe7" id="design-of-index-data-structure">Design of index data structure<a href="#design-of-index-data-structure" class="hash-link" aria-label="Direct link to Design of index data structure" title="Direct link to Design of index data structure">​</a></h4><ul><li>HashList: <code>HashID-&gt; List \&lt; (SeriesKey, SereesID) &gt;</code> for SeriesKey to interexamine with SereesID<ul><li>SereiesKey looks for the SereesID process: <code>Hash (SeriesKey) -&gt; HashID</code>, gets <code>List \&lt;SerisKey, SereesID &gt;</code> from HashList, and then traverses List for SeriesID.</li><li>SereesID looks for the SereesKey process, takes the 24-bit high of SeresID as HashID, and the search process is the same.</li></ul></li><li><code>TagValue -&gt; List  \&lt;SeriesID&gt; </code>implements indexing capabilities for Tag, using tag query conditions filtering.<ul><li>Query Conditions: <code>where tag = value</code>, get a list of SeresIDs based on TagValue, and further obtain FieldID loading data from TSM files.</li><li>Multiple query conditions intersect and or need to operate multiple <code>List\&lt;SereesID\&gt;</code>.</li></ul></li><li>The TagValue sequence is required to store traverse access. Used <code>show tag value</code> query HashList structure requires one maintenance, inert loading in memory. <code>HashID-&gt; List \&lt; (SeriesKey, SereesID) &gt;</code> and <code>TagValue-&gt; List \&lt;SeriesID&gt;</code> are persistent.</li></ul></li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="data-engine">Data Engine<a href="#data-engine" class="hash-link" aria-label="Direct link to Data Engine" title="Direct link to Data Engine">​</a></h4><p>Data used primarily to store time series data are usually scenes that write more and read less, using LSM models, mainly to write data quickly, while removing expired and deleted data through context. DataEngine is divided into the following modules:</p><ul><li><h4 class="anchor anchorWithStickyNavbar_LWe7" id="wal-module">WAL module<a href="#wal-module" class="hash-link" aria-label="Direct link to WAL module" title="Direct link to WAL module">​</a></h4><p>  For the pre-log, the WAL applies the write operation to the WAL file on disk before memory is added to the disk before memory, which will be used to restore memory to a state consistent with the collapse. When a write request is received, wal_job first checks whether the current WAL file is full, if it is full, create a new one, and then start writing it in a certain format. Each req corresponds separately to a seq-no, seq-no increment to record how many batches have been written since it started. The wal_job thread returns this seq_no to the main thread. Each point of the same batch has the same seq_no in memory or written to TSM, which is processed for seq_no.</p></li><li><h4 class="anchor anchorWithStickyNavbar_LWe7" id="timeseriesfamily">TimeSeriesFamily<a href="#timeseriesfamily" class="hash-link" aria-label="Direct link to TimeSeriesFamily" title="Direct link to TimeSeriesFamily">​</a></h4><p>  TimeSeriesFamily, a storage unit for time-order data that saves metadata for data in corresponding memory and data in corresponding disks, typically abbreviation for tsfamily, and before we write data, we generate SeresID and FieldID based on the tag and Field of the data. Coordinator gets Bucket based on db and Timemange and gets TseriesFamilyID to write data to tsfamily based on hash (SeriesID) % shard_nums. The tsfamily members are as follows:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pub struct TseriesFamily {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tf_id: u32，</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    delta_mut_cache: Arc \&lt;RwLock \&lt;MemCache&gt;&gt;，</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    delta_immut_cache: Vec \&lt;Arc \&lt;RwLock \&lt;MemCache&gt;&gt;&gt;，</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mut_cache: Arc \&lt;RwLock \&lt;MemCache&gt;&gt;，</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    immut_cache: Vec \&lt;Arc \&lt;RwLock \&lt;MemCache&gt;&gt;&gt;，</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    super_version: Arc \&lt;SuperVersion&gt;，</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    super_version_id: AtomicU64，</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    version: Arc \&lt;RwLock \&lt;Version&gt;&gt;，</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    opts: Arc \&lt;TseriesFamOpt&gt;，</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    seq_no: u64，</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    immut_ts_min: i64，</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mut_ts_max: i64，</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>  <code>tf_id</code>：tthe identifier of tsfamily, each tsfamily has the only tf_id.</p><p>  <code>mut-cache</code>：For the latest data written in a cache</p><p>  <code>immut-cache</code>：When the mut-cache is full, turn to <code>immut-chache</code>, <code>immut-cache</code> flash to disk to generate TSM files.</p><p>  <code>super-version</code>：Snapshot data from the current <code>mut-cache</code> and <code>immut-cache</code> of tsfimily.</p><p>  <code>version</code>：Maintains snapshots of disk data in the current tsfaimily.</p></li><li><h4 class="anchor anchorWithStickyNavbar_LWe7" id="recover-and-summary">Recover and Summary<a href="#recover-and-summary" class="hash-link" aria-label="Direct link to Recover and Summary" title="Direct link to Recover and Summary">​</a></h4><p>  Summmarry is a metadata file generated by changes in the version of the TSM file, which stores the sample file. The system file stores version-change metadata version_edit for outage recovery of <code>version_set</code> metadata. The node runs for a long time to generate larger summary files, and we regularly integrate the summary file to reduce the time of outage recovery.</p><p>  tskv first performs the recover function when creating:</p><ul><li>Gets the summary structure from the sample file. </li><li>According to the <code>last_seq</code> of ctx of the schema structure, know which batch has been filed by flush </li><li>According to the wal file and <code>last_seq</code>, the base that is not rewritten into memory by the flush </li><li>Restore <code>version_set</code> based on the summary file</li></ul></li><li><h4 class="anchor anchorWithStickyNavbar_LWe7" id="flush">Flush<a href="#flush" class="hash-link" aria-label="Direct link to Flush" title="Direct link to Flush">​</a></h4><p>  When the <code>immut-cache</code> capacity in tsfamily reaches a certain extent, the flash starts after the execution of the write operation, when it is found that the <code>immut-cache</code> is full, pack it into a <code>flash_request</code>, which is received by the <code>flash_job</code> thread after processing.</p><ul><li>Remove data from the <code>flash-request</code> and create a <code>flash_task</code> based on data, executed </li><li>According to <code>TseriesFamilyID</code>, FileID creates a TSM file that writes data to the TSM file </li><li>According to file information, the application metadata corresponds to the <code>Levels_info</code> of the version </li><li>Generate versioned it based on modifications to version and <code>seq-no</code>, TseriesFamilyID, etc </li><li>Send all generated <code>version edit</code> to the <code>summary_task_sender</code> created together at the time of creation of tskv, and the thread receives the request and starts processing, and writes the <code>version_edit</code> to the summary file.</li></ul></li><li><h4 class="anchor anchorWithStickyNavbar_LWe7" id="compaction">compaction<a href="#compaction" class="hash-link" aria-label="Direct link to compaction" title="Direct link to compaction">​</a></h4><p>  We use the class LSMtree method to sort data. Typically, data from time series databases are written in chronological manner. But IoT has scenarios that make up data, leading to time stamps. In addition, it is difficult to ensure the order of writing for all users due to network delays in public cloud scenarios. In the face of multiple complex write-in scenarios, we need to consider a variety of complex scenarios when performing data. </p><p>  The purpose of the operation is:</p><ul><li>Aggregate small tsm files to generate larger tsm files. </li><li>Clean up files that have expired or marked to delete. </li><li>Reduce reading magnification and maintain the metadata of <code>level_info</code> in our current version.</li></ul></li><li><h4 class="anchor anchorWithStickyNavbar_LWe7" id="level_range-compaction">level_range compaction<a href="#level_range-compaction" class="hash-link" aria-label="Direct link to level_range compaction" title="Direct link to level_range compaction">​</a></h4><p><img loading="lazy" alt="level_range" src="/assets/images/level_range-a142664c2b10fd21a459357c5359b3c9.jpg" width="1549" height="1492" class="img_ev3q"></p><ul><li>Typically, time series databases are written in order to respond to disorderly data, we add delta files. The data of Delta is brushed to the L0 layer. </li><li>From L1 to L3, The data of <code>LevelInfo</code> are classified by time. Each layer has a fixed time range and does not overlap, and the data in memcache has a fixed timerange. Each layer of time is dynamically updated when it works or flashes. </li><li>Each newly written TSM file has the latest time range of the layer. That is, <code>TimeRange ( ts_min, ts_max)</code>, <code>ts_max</code> is the largest in the time range held by file id largest TSM file in the L0 layer. </li><li>The pick process of the compact creates a virtual <code>time_window</code>. <code>time_window</code> selects the appropriate TSM file in this layer for compaction to the next floor, while updating the data of this layer <code>Level_info</code>. Update TSMin in <code>Level_info</code> to maximum timestamp of <code>time_window</code>, the time range of this layer goes forward. The newly generated TSM file is placed on the next floor and ts_max of the next layer is propelled to the maximum value of <code>time_window</code>. </li><li>At the beginning of L3, the TSM file is divided by directory by table; and the same table TSM file is placed together. Supports the generation of the parquet file and is graded on S3.</li></ul></li><li><h4 class="anchor anchorWithStickyNavbar_LWe7" id="time_window-compaction">time_window compaction<a href="#time_window-compaction" class="hash-link" aria-label="Direct link to time_window compaction" title="Direct link to time_window compaction">​</a></h4><p><img loading="lazy" alt="time_window" src="/assets/images/time_range-89f9f378ffca872fc8ab0827a6034abe.jpg" width="1630" height="1399" class="img_ev3q"></p><ul><li><p>Window-based components are performed in different lev_lange modes, from immut_cache flash to disk, generating different TSM files into the corresponding windows based on the time range of TSM, and windows are created dynamically over time. Each windows is responsible for writing for some time. </p></li><li><p>There are some discrete data tsm file blocks within windows that need to be merged to generate larger file blocks. The windows internal maintains a list of metadata about files. Compared with the mode of integration with Level_range, the performance of time_window reduces the amplification of writing.</p></li></ul></li><li><h4 class="anchor anchorWithStickyNavbar_LWe7" id="data_engine-data-stream">data_engine data stream<a href="#data_engine-data-stream" class="hash-link" aria-label="Direct link to data_engine data stream" title="Direct link to data_engine data stream">​</a></h4><p><img loading="lazy" alt="data_flow" src="/assets/images/data_engine-4280f73e5a9fe876fac01b232baa3843.jpg" width="2623" height="3619" class="img_ev3q"></p></li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="other-system-design">Other System Design<a href="#other-system-design" class="hash-link" aria-label="Direct link to Other System Design" title="Direct link to Other System Design">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="concession-of-tenants">Concession of tenants<a href="#concession-of-tenants" class="hash-link" aria-label="Direct link to Concession of tenants" title="Direct link to Concession of tenants">​</a></h4><ul><li><h4 class="anchor anchorWithStickyNavbar_LWe7" id="query-layer">query layer<a href="#query-layer" class="hash-link" aria-label="Direct link to query layer" title="Direct link to query layer">​</a></h4><p>In DataFusion, the catalog isolation relationship is divided into <code>catalog/schema/table</code>. We use this isolation relationship, which is separated between tenants as <code>tenant (namespace) / database / table</code>.</p><ul><li>Table corresponds to a specific table in a specific database that provides a specific table schema definition implementation TableProvider</li><li>Database corresponds to a dataabase, which manages multiple tables under a specific database.</li><li>Namespace corresponds to Catalog. Each tenant occupies only one catalog, and the db seen in different tenants is different, and different tenants can use the same Database name. When the user logs in, take TenantID in the session by default to see his namespace, which means namespace has a soft isolation effect.</li></ul></li><li><h4 class="anchor anchorWithStickyNavbar_LWe7" id="tskv-layer">tskv layer<a href="#tskv-layer" class="hash-link" aria-label="Direct link to tskv layer" title="Direct link to tskv layer">​</a></h4><p>The directory segmentation policy mentioned in the above introduction: <code>/User/db/book/replicationset_id/vnode_id/tskv</code> is an instance on each Node node. Save all Vnote information on the current Node. Each Vnode saves the data under a separate directory. Clean up the data based on the configuration db retion policy. At the same time, we can easily carry out the data directory size statistics, the tenant is billed.</p></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="compression-algorithm">Compression Algorithm<a href="#compression-algorithm" class="hash-link" aria-label="Direct link to Compression Algorithm" title="Direct link to Compression Algorithm">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="delta">DELTA<a href="#delta" class="hash-link" aria-label="Direct link to DELTA" title="Direct link to DELTA">​</a></h3><p>Mainly used for timestamp, integer and unsigned integer.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="principle">Principle<a href="#principle" class="hash-link" aria-label="Direct link to Principle" title="Direct link to Principle">​</a></h4><p>First, the difference is made, that is, the first data is unchanged, other data are transformed into delta with the previous data, and all numbers are processed byzigzag, i64 is mapped to u64, specifically to zero, negative numbers are mapped to odd numbers, such as <!-- -->[0, 1, 2]<!-- --> after zigzag processing to <!-- -->[0, 1,2]<!-- --> and maximum convention numbers are calculated. Then judge that if all deltas are the same, use the cruise path code directly, that is, only the first value, delta, and the number of data. Otherwise, all delta values are divided into maximum convention numbers (maximum convention numbers are encoded into data), and then encoded using Simple 8b.</p><p><img loading="lazy" src="/assets/images/simple8b-3443de672234bc38b690b4198b41e18d.png" width="688" height="128" class="img_ev3q"></p><p>Simple 8b is a compression algorithm that encapsulates multiple integers to a 64-bit integer, the first four-bit as selector to specify the number and validity of integers stored in the remaining 60 bits, and the latter 60 bits are used to store multiple integers. In addition, when delta is larger than the maximum range of Simple 8b energy encoding (more than 1&lt;60-1, generally not) does not compress and stores arrays directly.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="applicability">Applicability<a href="#applicability" class="hash-link" aria-label="Direct link to Applicability" title="Direct link to Applicability">​</a></h4><p>In some time-consuming data, assuming that data is collected every five seconds, the time stamp is 5, that all timestamps can be restored through only three numbers, with extremely high compression, while some delta does not guarantee consistent scenarios, i.e., where using Simple 8b, are more suitable for smaller, floating data.</p><p>In the absence of specifying compression algorithms, we use this compression algorithm for timemarks, integer and unsigned integers, and the compression rate is higher.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="gorilla">GORILLA<a href="#gorilla" class="hash-link" aria-label="Direct link to GORILLA" title="Direct link to GORILLA">​</a></h3><p>Mainly used for floating point type.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="principle-1">Principle<a href="#principle-1" class="hash-link" aria-label="Direct link to Principle" title="Direct link to Principle">​</a></h4><p>The principle of Gorilla is similar to the difference, the difference is that the difference is the difference between two data, and gorilla is different or different. The first data is not processed at the time of coding, and if the previous data is different from the previous data, if the difference or value is 0, repeat it with the previous data, write a patch to represent repetition, and, if not zero, calculate the first zero and back derivative zeros of the heterogeneous or value delta. If the number is the same, only the intermediate valid bit is encoded. If the number is different, the first 0.5 bits are derived, the back 0. 5 bits are written, and then the intermediate valid bit is written.</p><p><img loading="lazy" src="/assets/images/gorilla-d512ade3b84ed8a02213308162a5a61c.png" width="695" height="372" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="applicability-1">Applicability<a href="#applicability-1" class="hash-link" aria-label="Direct link to Applicability" title="Direct link to Applicability">​</a></h4><p>As compared with delta type, it is also suitable for time-order data scenarios, and we may collect data in different locations, but the toponymic-related information collected at the same location is generally consistent, in which the compression rate is higher than that of compression efficiency.</p><p>In the absence of specifying compression algorithms, we specify this compression algorithm for floating point type by default.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="quantile">QUANTILE<a href="#quantile" class="hash-link" aria-label="Direct link to QUANTILE" title="Direct link to QUANTILE">​</a></h3><p>Mainly used for timestamps, integers, unsigned integers and floating points.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="principle-2">Principle<a href="#principle-2" class="hash-link" aria-label="Direct link to Principle" title="Direct link to Principle">​</a></h4><p>Qantile supports multiple levels of compression, and CosDB currently uses the default compression level.</p><p>Each data is described by Huffman coding and offset, and the offset specifies the exact location of the range of the data by the Huffman code corresponding to the range of the data. For each block compression, the difference processing is first carried out, the data after the difference is replaced by the current data, then the current array is divided into multiple blocks at an interval of 128, each block determines a range and associated metadata, while calculating the maximum number of conventions per block, optimizes the number of conventions as appropriate, and merges some adjacent blocks, then determines its Huffman encoding based on the weight of each block in the data, and finally encodes the data using them.</p><p><img loading="lazy" src="/assets/images/quantile-a5f0c8ef16ea2d3344c0476bb2c8901c.png" width="767" height="621" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="applicability-2">Applicability<a href="#applicability-2" class="hash-link" aria-label="Direct link to Applicability" title="Direct link to Applicability">​</a></h4><p>Compared with the delta algorithm and the gorilla algorithm, because the difference algorithm is also used, it is roughly the same in the selection of applicable data.</p><p>The longitudinal axis of the image is the compression ratio, the time is only relative.</p><p><img loading="lazy" src="/assets/images/f64_codec-1607885db67be2e917a1205f1f745944.png" width="755" height="448" class="img_ev3q"></p><p><img loading="lazy" src="/assets/images/i64_codec-d3d629eae23dd4e6fc8c05f0f474c0cf.png" width="755" height="448" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="bitpack">BITPACK<a href="#bitpack" class="hash-link" aria-label="Direct link to BITPACK" title="Direct link to BITPACK">​</a></h3><p>Mainly used for Boolean types.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="principle-3">Principle<a href="#principle-3" class="hash-link" aria-label="Direct link to Principle" title="Direct link to Principle">​</a></h4><p>The size of a bool-type data is a byte, and for the information that bool represents, it<!-- -->&#x27;<!-- -->s only one bit to represent so that we can assemble eight bool-type data into one byte.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="applicability-3">Applicability<a href="#applicability-3" class="hash-link" aria-label="Direct link to Applicability" title="Direct link to Applicability">​</a></h4><p>No matter what data, we can ensure a compression ratio of nearly eight times that we specify this compression algorithm for the Boolean type by default without specifying the compression algorithm.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="string-compression-algorithm">String Compression Algorithm<a href="#string-compression-algorithm" class="hash-link" aria-label="Direct link to String Compression Algorithm" title="Direct link to String Compression Algorithm">​</a></h3><p>The string compression algorithm currently supported is compressed, such as below.</p><p><img loading="lazy" src="/assets/images/str_comrpess_ratio-7eb7773f58048541e4798250f121a9f4.png" width="758" height="448" class="img_ev3q"></p><p>And compressed time and decompression time, units are us.</p><p><img loading="lazy" src="/assets/images/str_compress_time-f366e655dbe2796baf1ac983e17a8b07.png" width="758" height="448" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="snappy">SNAPPY<a href="#snappy" class="hash-link" aria-label="Direct link to SNAPPY" title="Direct link to SNAPPY">​</a></h3><p>Snappy algorithms are not designed to minimize compression or are not designed to be compatible with any other compression library. Instead, its goal is to be very high compression efficiency and reasonable compression rates, so it is recommended to use snappy more efficiently.</p><p>In the absence of specifying a string compression algorithm, we specify this compression algorithm by default.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="zstd">ZSTD<a href="#zstd" class="hash-link" aria-label="Direct link to ZSTD" title="Direct link to ZSTD">​</a></h3><p>Zstd supports multiple compression levels, and CnosDB currently uses the default compression level.</p><p>Zstd, known as Zstand, is a fast compression algorithm that provides high compression ratio, and Zstt uses a finite state entropy encoder. A very powerful compromise scheme for compression speed/compression rate is provided.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="gzipzlib">GZIP/ZLIB<a href="#gzipzlib" class="hash-link" aria-label="Direct link to GZIP/ZLIB" title="Direct link to GZIP/ZLIB">​</a></h3><p>Gzip is similar to zlib. For files to be compressed, a variant of the LZ77 algorithm is first used to compress the results by using Huffman coding, with high compression rate but also time-consuming. Both algorithms are widely used and have similar performances and can be selected according to the situation.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="bzip">BZIP<a href="#bzip" class="hash-link" aria-label="Direct link to BZIP" title="Direct link to BZIP">​</a></h3><p>Compared with several other algorithms, the compression rate is higher, but the compression efficiency is lower, which can be used for scenarios that require extreme compression rate, in general less recommended.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="quorum-algorithm">Quorum Algorithm<a href="#quorum-algorithm" class="hash-link" aria-label="Direct link to Quorum Algorithm" title="Direct link to Quorum Algorithm">​</a></h2><p>Quorum algorithm is a voting algorithm commonly used in distributed systems to ensure data redundancy and eventual consistency. Quorum is used to ensure that if some participants fail, we can still collect votes from the surviving participants and continue to execute the algorithm. A Quorum represents the minimum number of votes needed to perform an action, typically a majority of participants. The core idea behind Quorum is that even if participants fail or happen to be separated by network partitions, at least one of them can act as an arbiter to ensure the accuracy of the protocol.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="basic-principle-of-quorum-algorithm">Basic Principle of Quorum Algorithm<a href="#basic-principle-of-quorum-algorithm" class="hash-link" aria-label="Direct link to Basic Principle of Quorum Algorithm" title="Direct link to Basic Principle of Quorum Algorithm">​</a></h3><p>There are three parameters in Quorum URW algorithm: N, R, W. </p><p>Parameter N is also called a copy factor, meaning a number of copies of data throughout the cluster. </p><p>Parameter R is the level of read consistency, which means successful reading from R copies will be considered a successful reading operation. </p><p>Parameter W is the level of writing consistency, which means successfully written from W copies, will be considered a successful writing operation.</p><p>N, R and W parameters can achieve different consistency levels under different combination conditions:</p><ol><li>When &quot;W + R &gt; N&quot;, the latest data can be determined by timestamp, version number, etc. In other words, under the combination of parameters that meet this condition, the strong consistency of data can be realized.</li><li>When &quot;W + R &lt; = N&quot; is not possible, it can only guarantee final consistency, i.e. system reading may obtain old data.</li><li>When &quot;W = N, R = 1, so-called Write All Read One&quot; is the scenario of the CP model in CAP theory.</li><li>When &quot;W &lt;N, R = 1&quot; is the scene of the AP model in CAP theory.</li></ol><h3 class="anchor anchorWithStickyNavbar_LWe7" id="modalities-for-data-consistency-assurance">Modalities for Data Consistency Assurance<a href="#modalities-for-data-consistency-assurance" class="hash-link" aria-label="Direct link to Modalities for Data Consistency Assurance" title="Direct link to Modalities for Data Consistency Assurance">​</a></h3><p>Data are required to write N when writing, taking into account that there may be write failures in reality, loss of data copies caused by machine failures, and inconsistencies in multiple copies of data, such as write-and-end.</p><ol><li>The hinted-handoff mechanism is a machine received to write requests. When a remote replaica is written in failure, it is stored in the hinted-handoff queue of the machine; this opportunity regularly sends the contents of the hinted-handoff queue to a remote node to achieve final consistency in the data. Typically, the hinted-handoff queue has a capacity limit, and overcapacity writes will fail.</li><li>Reading repair mechanism If two data are found to be inconsistent when read, repairs are made to the final consistency of data based on version number, timestamp or other copy information; reading and repairs are usually used in the CP model.</li><li>In this distributed algorithm of Quorum, the deletion operation is a special operation to deal with the problem that there may be no resurrection of old data. For example, three copies, two successful deletions of one unsuccessful, and the failure to delete successful data processing may be used as valid data synchronization to cause the resurrection of deleted data; in order to address this situation, marker deletion is usually used when deleted, and is later really deleted from disk, which is often referred to as a tombstone mechanism.</li><li>The anti-entry anti-entropy mechanism is similar to a background checker, where there is a lack of data between copies and where values exist and are not consistent and then repaired. This mechanism is usually costly for the system, and most systems have a configuration switch when implemented, which is determined by users whether to open.</li></ol><p>It is because of the large cost of the system that the antitropy mechanism is different when it is implemented, different systems choose to realize it according to different particle size. Some systems routinely view only whether one data block content is lost without carsandra, while some systems validate each content within the periodic calibration system, such as liak. In content-based consistency implementations, this data structure is usually built on Merkel Tree.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="cloud-native">Cloud Native<a href="#cloud-native" class="hash-link" aria-label="Direct link to Cloud Native" title="Direct link to Cloud Native">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="basic-concepts-of-cloud-native">Basic Concepts of Cloud Native<a href="#basic-concepts-of-cloud-native" class="hash-link" aria-label="Direct link to Basic Concepts of Cloud Native" title="Direct link to Basic Concepts of Cloud Native">​</a></h3><p>Cloud-native time series Database is a kind of Database as a Service (DBaaS), which completes the construction, deployment and delivery of the database through the cloud platform. It is primarily a cloud platform that provides services, providing models that allow organizations, end users and respective applications to store, manage and retrieve data from the cloud. Cloud databases provide a scalable and reliable database solution. Clients have service levels specific to their cloud environment. It is deployed in a non-virtualized environment, making the full extent of the underlying hardware available for the database.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="advantage-of-cloud-native-database">Advantage of Cloud Native Database<a href="#advantage-of-cloud-native-database" class="hash-link" aria-label="Direct link to Advantage of Cloud Native Database" title="Direct link to Advantage of Cloud Native Database">​</a></h3><p>For example, cloud database services provided by cloud service providers such as AWS, Microsoft Azure, Ali Cloud, Google Cloud, and CnosDB have contributed to the development of cloud-native databases. As a result, the market share of cloud databases has been growing rapidly in recent years. More and more enterprises and organizations are migrating their business from local data centers to the cloud. Cloud platforms provide high elasticity, strict service level agreements to ensure reliability and ease of management, while reducing operational costs. Cloud databases play a key role in supporting cloud-based business. It becomes the central hub connecting the underlying resources to various applications, making it a critical system for the cloud.</p><ul><li>Better security. A cloud-native database may seem like a very remote and invisible place to store valuable information. It is more secure than users think. With the help of proper antivirus and firewall and some rules, data can be effectively protected. In addition, keeping up to date software technologies guarantees that cloud computing can provide a higher quality of data protection for businesses dealing with sensitive information.</li><li>More available space. This is one of the most useful aspects of cloud-native databases, which can store large amounts of data without multiple USB drives.</li><li>Enhance collaboration. With a database accessible from anywhere in this service, cloud-native databases create the perfect collaboration tool, especially for colleagues who are geographically distributed, making it easy for all team members to collaborate without the danger of losing or duploking work.</li><li>Cost effective. Cloud-native databases are cost-effective because paying for unlimited storage in the cloud at one time is more cost-effective than having to purchase or repair multiple hard drives in a row. If we buy relatively cheap hard drives, they are easily lost or damaged, so they are costly to maintain in the long run. So, with this cloud-native database, users can buy as much storage space as they need related to their workflow.</li><li>Redundancy. Cloud computing provides replicas and systems that can be used in the event of failure. These replicas can be accessed by replicating the data on multiple computers within the same database. These services help users ensure that their information is always available to them, even if something unexpected happens.</li><li>Highly scalable. The cloud native distributed database is separated from the underlying cloud computing infrastructure, so it can flexibly mobilize resources in time to expand or shrink, so as to calmly cope with the pressure brought by the surge in traffic and the waste caused by excess resources during the traffic valley. The characteristics of ecological compatibility also make the cloud native database have strong portability.</li><li>Ease of use. The cloud-native distributed database is easy to use, and its computing nodes are deployed in the cloud and can be accessed from multiple frontends anytime and anywhere. Because the cluster is deployed on the cloud, the impact of a single point of failure on the service is very small through automated disaster recovery and high availability. When the service needs to be upgraded or replaced, the nodes can also be upgraded by rotation without interrupting the service.</li><li>Fast iteration. Each service in the cloud-native distributed database is independent of each other, and the update of a single service will not affect other parts. In addition, cloud-native development testing and operations tools are highly automated, which allows for more agile updates and iterations.</li><li>Cost savings. Building a data center is an independent and complete project that requires a large amount of hardware investment and professional operations personnel to manage and maintain the data center. Continuous operation and maintenance can also cause a lot of financial pressure. Cloud-native distributed databases obtain a scalable database and achieve more optimized resource allocation at a lower upfront cost.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="shared-storage-vs-shared-nothing-storage">Shared Storage VS Shared-Nothing Storage<a href="#shared-storage-vs-shared-nothing-storage" class="hash-link" aria-label="Direct link to Shared Storage VS Shared-Nothing Storage" title="Direct link to Shared Storage VS Shared-Nothing Storage">​</a></h3><p>A shared memory architecture is a storage system that is used by multiple users/computers. It stores all files in a centralized storage pool and allows multiple users to access them simultaneously. For the upper computing nodes, the shared memory architecture provides a uniform data access interface for multiple users, and users do not need to care about the actual data distribution in the system, nor do they need to care about the load balancing problem of data distribution. In the shared storage architecture, cloud vendors can pool disk resources, let multiple users share a distributed storage cluster, and pay according to the actual use of capacity. This business model is more in line with the current market demand. The diagram is as follows:</p><p><img loading="lazy" alt="共享存储架构" src="/assets/images/share_everything-e5e06c4ef8af36d991848bf8a7882f0f.png" width="522" height="279" class="img_ev3q"></p><p>The shared-nothing storage architecture is a relatively old pattern that has recently seen a resurgence in data storage technologies, especially in the NoSQL, data warehousing, and big data domains. As the architecture evolves, it has some very interesting performance tradeoffs compared to the more common simple shared memory architecture.</p><p>Shared-nothing architecture is an architecture used for distributed computing, where each node is independent and different nodes are interconnected through a network. Each node consists of a processor, main memory, and disk. The main motivation for this architecture is to eliminate contention between nodes. The nodes here do not share memory or storage. Disks have a single node that cannot be shared. It works effectively in high volume and read/write environments. The diagram is shown below.</p><p><img loading="lazy" alt="无共享存储架构" src="/assets/images/share_nothing-b6595afd07d8eef0032eac385a6c9b32.png" width="593" height="249" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="single-tenant-model-vs-multi-tenant-model">Single Tenant Model VS Multi Tenant Model<a href="#single-tenant-model-vs-multi-tenant-model" class="hash-link" aria-label="Direct link to Single Tenant Model VS Multi Tenant Model" title="Direct link to Single Tenant Model VS Multi Tenant Model">​</a></h2><p>Single tenant model means that only one cloud software solution instance is running on its supported hardware and infrastructure components. Not shared with multiple customers involved in a single-tenant environment. In a multi-tenant environment, the cloud infrastructure is shared among multiple customers or accounts. No single customer has control over how resources are allocated or consumed.</p><p>CnosDB uses a multi-tenant model. Multi-tenancy is a solution to provide Software as a Service (SaaS) in the cloud. Multi-tenancy uses a shared infrastructure to provide access to a SaaS solution to multiple customers. Multi-tenancy means that a single instance of the software and its supporting infrastructure serve multiple customers. Each customer shares the software application and also shares a database. Each tenant&#x27;s data is isolated and not visible to other tenants.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="多租户的潜在好处">多租户的潜在好处<a href="#多租户的潜在好处" class="hash-link" aria-label="Direct link to 多租户的潜在好处" title="Direct link to 多租户的潜在好处">​</a></h4><p>-Low cost: Multiple customers imply shared environment costs, and these savings (from SaaS providers) are often transferred into software costs.
-Integration: The cloud environment allows easier integration with other applications through the use of apis.</p><ul><li>Easy to maintain: The server is technically owned by the SaaS vendor, which means that some level of database maintenance is handled by the vendor rather than you maintaining the environment yourself.</li></ul><p>The multi-tenancy model of cloud-native time series database is usually a SaaS multi-tenancy model. Compared with the previous single-tenant model, it has many advantages.</p><p>-Cost reduction through economies of scale: With multi-tenancy, scaling has a much smaller impact on the infrastructure than with single-tenant hosting solutions because new users have access to the same basic software.
-Shared infrastructure leads to cost reduction: SaaS allows companies of all sizes to share infrastructure and data center operating costs. There is no need to add applications and more hardware to their environment. There is no need to configure or manage any infrastructure or software outside of internal resources, enabling enterprises to focus on their daily tasks.</p><ul><li>Continuous maintenance and updates: Customers can keep their software up to date without paying expensive maintenance. Vendors roll out new features and updates. These are often included in SaaS subscriptions.</li><li>Configuration can be done while keeping the underlying codebase unchanged: Single-tenant hosting solutions are often custom and require changes to the application&#x27;s code. This customization is costly, and upgrading is time consuming because the upgrade may not be compatible with your environment.</li></ul><p>Multi-tenant solutions are designed to be highly configurable so that enterprises can make applications run the way they want. No code or data structures need to be changed, making the upgrade process simple.</p><p>Multi-tenant architectures also allow database products to efficiently serve everyone, from small customers whose scale may not warrant dedicated infrastructure, to large enterprises that need access to virtually unlimited cloud computing resources. Software development and maintenance costs are amortized, resulting in lower expenditures, resulting in cost savings for users.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="serverless-vs-dedicate">Serverless VS Dedicate<a href="#serverless-vs-dedicate" class="hash-link" aria-label="Direct link to Serverless VS Dedicate" title="Direct link to Serverless VS Dedicate">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="serverless-introduction">Serverless Introduction<a href="#serverless-introduction" class="hash-link" aria-label="Direct link to Serverless Introduction" title="Direct link to Serverless Introduction">​</a></h4><p>As a new cloud computing paradigm, Serverless architecture is a revolutionary architecture in the cloud native era, which subverts the traditional understanding of software application deployment and operation. Serverless is a cloud-native development model that allows developers to build and run applications without managing servers. There are still servers in Serverless, but they are abstracted from application development. Cloud providers handle the day-to-day work of configuring, maintaining, and scaling the server infrastructure. Developers can simply package their code into containers for deployment. Once deployed, the Serverless application responds to demand and automatically scales up and down as needed. Serverless offerings from public cloud providers are typically metered on demand through an event-driven execution model. Therefore, when the Serverless service is idle, it incurs no cost.</p><p>The Serverless pattern differs from other cloud computing models in that the cloud provider is responsible for managing the scaling of the cloud infrastructure and applications. Serverless applications are deployed in containers that start automatically on demand when called.</p><p>Under the standard Infrastructure as a Service (IaaS) cloud computing model, users pre-purchase units of capacity, which means that users need to pay public cloud providers for alway online server components to run their applications. It is the user&#x27;s responsibility to expand the server capacity when demand is high and to shrink it when that capacity is no longer needed. The cloud infrastructure required to run the application is active even when the application is unused.</p><p>In contrast, for Serverless architectures, applications are started only when needed. When an event triggers the application code to run, the public cloud provider dynamically allocates resources for that code. When the code finishes executing, the user stops paying. In addition to cost and efficiency advantages, Serverless frees developers from routine and trivial tasks related to application scaling and server configuration.</p><p>With Serverless, everyday tasks such as managing the operating system and file system, security patching, load balancing, capacity management, scaling, logging, and monitoring are offloaded to the cloud service provider, reducing the human cost required by the user.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="advantage-of-serverless">Advantage of Serverless<a href="#advantage-of-serverless" class="hash-link" aria-label="Direct link to Advantage of Serverless" title="Direct link to Advantage of Serverless">​</a></h4><ul><li>Serverless can increase developer productivity and reduce operational costs. Freed from the daily tasks of configuring and managing servers, developers have more time to focus on their application development efforts.</li><li>Serverless facilitates DevOps adoption because it reduces the need for developers to explicitly describe the infrastructure they need to operate to configure for them.</li><li>Further simplifying application development by incorporating entire components from third-party Backend as a Service (BaaS) products.
-The operational cost of the Serverless model is reduced because the user can pay for the cloud-based computing time as needed instead of running and managing its servers all the time.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="disadvantage-of-serverless">Disadvantage of Serverless<a href="#disadvantage-of-serverless" class="hash-link" aria-label="Direct link to Disadvantage of Serverless" title="Direct link to Disadvantage of Serverless">​</a></h4><ul><li>Not running your own server or controlling your own server-side logic can create corresponding problems.</li><li>Cloud providers may have strict restrictions on how their components interact, which in turn affects the flexibility and degree of customization of the user&#x27;s own system. In a BaaS environment, developers may rely on services whose code is not under their control.</li><li>Giving up control over these aspects of the IT stack also leaves users vulnerable to vendor lock-in. The decision to switch suppliers may also be accompanied by the cost of upgrading the system to conform to the new supplier specification.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="dedicated-introduction">Dedicated Introduction<a href="#dedicated-introduction" class="hash-link" aria-label="Direct link to Dedicated Introduction" title="Direct link to Dedicated Introduction">​</a></h4><p>Dedicate mode, that is, one client for each server, which is the service method used by traditional database vendors. Dedicate model can effectively solve the shortcomings of Serverless, but it does not have the advantages of Serverless.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="serverless-or-dedicate">Serverless or Dedicate<a href="#serverless-or-dedicate" class="hash-link" aria-label="Direct link to Serverless or Dedicate" title="Direct link to Serverless or Dedicate">​</a></h3><p>Serverless and Dedicate each have their own advantages, so when making a package choice, you can refer to the following content to complete the selection.</p><ul><li>Serverless<ul><li>When automatic elastic scaling is required. Automatically scale up/down and react instantly to changes in requirements. This is especially critical for businesses with dramatically increasing or unpredictable workloads.</li><li>When minimization is required. Your team can spend less time worrying about the database and more time building your application.</li><li>When testing, experimenting, or evaluating. Suitable for lightweight applications, prototyping, testing and development environments, side projects, etc., because they are self-service and fast.</li><li>When cost minimization is required. Charges are based on actual storage and computation usage. The resources allocated by the database automatically increase and decrease with demand.</li></ul></li><li>Dedicate<ul><li>When hardware control is required. Severless is cloud-based and does not control the hardware. Solutions that can control hardware are needed for security or regulatory reasons.</li><li>When a deep feature set is needed. Serverless features are still relatively limited. Some companies need a database with multiple regional capabilities.
-When security concerns are excluded from multi-tenancy. In the end, tenants still share the same machine. For high-security workloads, Dedicate has its advantages.</li><li>When providing better performance or less cost. Severless is the best choice for many use cases, but there is no &quot;perfect&quot; database solution that meets all possible use cases/workloads.</li></ul></li></ul><p>Based on the above references, users can choose the appropriate package type for their needs and usage situation. CnosDB can provide users with Serverless and Dedicate two package modes to meet the needs of users to the greatest extent.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/cnosdb/docs/docs/reference/design.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/category/reference"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Reference</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/reference/rest_api"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">REST API</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#concepts" class="table-of-contents__link toc-highlight">Concepts</a><ul><li><a href="#background" class="table-of-contents__link toc-highlight">Background</a></li><li><a href="#time-series" class="table-of-contents__link toc-highlight">Time Series</a></li><li><a href="#data-model" class="table-of-contents__link toc-highlight">Data Model</a></li></ul></li><li><a href="#architecture" class="table-of-contents__link toc-highlight">Architecture</a><ul><li><a href="#design-objectives" class="table-of-contents__link toc-highlight">Design Objectives</a></li><li><a href="#data-replication-and-consensus" class="table-of-contents__link toc-highlight">Data Replication and Consensus</a></li><li><a href="#meta-cluster" class="table-of-contents__link toc-highlight">Meta Cluster</a></li><li><a href="#sql-engine" class="table-of-contents__link toc-highlight">SQL Engine</a></li><li><a href="#tskv-index-and-data-storage" class="table-of-contents__link toc-highlight">TSKV Index and Data Storage</a></li><li><a href="#other-system-design" class="table-of-contents__link toc-highlight">Other System Design</a></li></ul></li><li><a href="#compression-algorithm" class="table-of-contents__link toc-highlight">Compression Algorithm</a><ul><li><a href="#delta" class="table-of-contents__link toc-highlight">DELTA</a></li><li><a href="#gorilla" class="table-of-contents__link toc-highlight">GORILLA</a></li><li><a href="#quantile" class="table-of-contents__link toc-highlight">QUANTILE</a></li><li><a href="#bitpack" class="table-of-contents__link toc-highlight">BITPACK</a></li><li><a href="#string-compression-algorithm" class="table-of-contents__link toc-highlight">String Compression Algorithm</a></li><li><a href="#snappy" class="table-of-contents__link toc-highlight">SNAPPY</a></li><li><a href="#zstd" class="table-of-contents__link toc-highlight">ZSTD</a></li><li><a href="#gzipzlib" class="table-of-contents__link toc-highlight">GZIP/ZLIB</a></li><li><a href="#bzip" class="table-of-contents__link toc-highlight">BZIP</a></li></ul></li><li><a href="#quorum-algorithm" class="table-of-contents__link toc-highlight">Quorum Algorithm</a><ul><li><a href="#basic-principle-of-quorum-algorithm" class="table-of-contents__link toc-highlight">Basic Principle of Quorum Algorithm</a></li><li><a href="#modalities-for-data-consistency-assurance" class="table-of-contents__link toc-highlight">Modalities for Data Consistency Assurance</a></li></ul></li><li><a href="#cloud-native" class="table-of-contents__link toc-highlight">Cloud Native</a><ul><li><a href="#basic-concepts-of-cloud-native" class="table-of-contents__link toc-highlight">Basic Concepts of Cloud Native</a></li><li><a href="#advantage-of-cloud-native-database" class="table-of-contents__link toc-highlight">Advantage of Cloud Native Database</a></li><li><a href="#shared-storage-vs-shared-nothing-storage" class="table-of-contents__link toc-highlight">Shared Storage VS Shared-Nothing Storage</a></li></ul></li><li><a href="#single-tenant-model-vs-multi-tenant-model" class="table-of-contents__link toc-highlight">Single Tenant Model VS Multi Tenant Model</a><ul><li><a href="#serverless-vs-dedicate" class="table-of-contents__link toc-highlight">Serverless VS Dedicate</a></li><li><a href="#serverless-or-dedicate" class="table-of-contents__link toc-highlight">Serverless or Dedicate</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/cnosdb" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/cnosdb" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/cnosdb/cnosdb" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.093b838e.js"></script>
<script src="/assets/js/main.3280fb8b.js"></script>
</body>
</html>