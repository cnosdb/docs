"use strict";(self.webpackChunkCnosDB=self.webpackChunkCnosDB||[]).push([[5213],{4137:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>h});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),p=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},d=function(e){var t=p(e.components);return n.createElement(l.Provider,{value:t},e.children)},u="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),u=p(a),m=r,h=u["".concat(l,".").concat(m)]||u[m]||c[m]||o;return a?n.createElement(h,s(s({ref:t},d),{},{components:a})):n.createElement(h,s({ref:t},d))}));function h(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,s=new Array(o);s[0]=m;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[u]="string"==typeof e?e:r,s[1]=i;for(var p=2;p<o;p++)s[p]=a[p];return n.createElement.apply(null,s)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},5343:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>c,frontMatter:()=>o,metadata:()=>i,toc:()=>p});var n=a(7462),r=(a(7294),a(4137));const o={sidebar_position:7},s="Eco-integration",i={unversionedId:"reference/ecosystem",id:"reference/ecosystem",title:"Eco-integration",description:"Telegraf",source:"@site/docs/reference/ecosystem.md",sourceDirName:"reference",slug:"/reference/ecosystem",permalink:"/docs/reference/ecosystem",draft:!1,editUrl:"https://github.com/cnosdb/docs/docs/reference/ecosystem.md",tags:[],version:"current",sidebarPosition:7,frontMatter:{sidebar_position:7},sidebar:"tutorialSidebar",previous:{title:"Configuration",permalink:"/docs/reference/config"},next:{title:"Benchmark",permalink:"/docs/reference/performance"}},l={},p=[{value:"Telegraf",id:"telegraf",level:2},{value:"<strong>Telegraf Introduction</strong>",id:"telegraf-introduction",level:3},{value:"User scenarios",id:"user-scenarios",level:4},{value:"<strong>Telegraf Deployment</strong>",id:"telegraf-deployment",level:3},{value:"<strong>Telegraf Configuration</strong>",id:"telegraf-configuration",level:3},{value:"Cnos-Telegraf",id:"cnos-telegraf",level:2},{value:"<strong>Description of the changes compared to Telegraf</strong>",id:"description-of-the-changes-compared-to-telegraf",level:3},{value:"Parser Plugin",id:"parser-plugin",level:4},{value:"Output Plugin",id:"output-plugin",level:4},{value:"Input Plugin",id:"input-plugin",level:4},{value:"<strong>Build</strong>",id:"build",level:3},{value:"<strong>Start</strong>",id:"start",level:3},{value:"Grafana",id:"grafana",level:2},{value:"Introduction",id:"introduction",level:3},{value:"Grafana Deployment",id:"grafana-deployment",level:3},{value:"Grafana Configuration",id:"grafana-configuration",level:3},{value:"Prometheus",id:"prometheus",level:2},{value:"Introduction",id:"introduction-1",level:3},{value:"Precondition",id:"precondition",level:3},{value:"Remote Write",id:"remote-write",level:3},{value:"Remote Read",id:"remote-read",level:3},{value:"TensorFlow",id:"tensorflow",level:2},{value:"Use CnosDB and TensorFlow for time series prediction",id:"use-cnosdb-and-tensorflow-for-time-series-prediction",level:3},{value:"From three-body motion to Sunspot Change prediction",id:"from-three-body-motion-to-sunspot-change-prediction",level:3},{value:"Introduction",id:"introduction-2",level:4},{value:"Introduction to the Sunspot Change Observation dataset",id:"introduction-to-the-sunspot-change-observation-dataset",level:4},{value:"Import Data to CnosDB",id:"import-data-to-cnosdb",level:3},{value:"Use TSDB CnosDB to store MSSN data",id:"use-tsdb-cnosdb-to-store-mssn-data",level:4},{value:"Use CnosDB Python Connector to Connect and Use CnosDB Database",id:"use-cnosdb-python-connector-to-connect-and-use-cnosdb-database",level:4},{value:"CnoDB reads the data and uses TensorFlow to reproduce the 1DConv+LSTM network to predict sunspot changes",id:"cnodb-reads-the-data-and-uses-tensorflow-to-reproduce-the-1dconvlstm-network-to-predict-sunspot-changes",level:3},{value:"Use CnosDB to Read Data",id:"use-cnosdb-to-read-data",level:4},{value:"Divide the data into training set and test set",id:"divide-the-data-into-training-set-and-test-set",level:4},{value:"Use the Sliding Window Method to Construct the Training Data",id:"use-the-sliding-window-method-to-construct-the-training-data",level:4},{value:"Use the tf.keras module to Define the 1DConv+LSTM Neural Network Model",id:"use-the-tfkeras-module-to-define-the-1dconvlstm-neural-network-model",level:4},{value:"Predict the MSSN using the trained model",id:"predict-the-mssn-using-the-trained-model",level:4},{value:"Visualization of the results compared to the ground truth",id:"visualization-of-the-results-compared-to-the-ground-truth",level:4}],d={toc:p},u="wrapper";function c(e){let{components:t,...o}=e;return(0,r.kt)(u,(0,n.Z)({},d,o,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"eco-integration"},"Eco-integration"),(0,r.kt)("h2",{id:"telegraf"},"Telegraf"),(0,r.kt)("h3",{id:"telegraf-introduction"},(0,r.kt)("strong",{parentName:"h3"},"Telegraf Introduction")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/influxdata/telegraf"},"Telegraf")," is an open source server agent program used to collect metrics from stacks, sensors, and systems to database intensively, with a minimal memory footprint and support for extensions via plug-ins.Telegraf is simple to configure, easy to get started with, and greatly reducing the difficulty of data acquisition compared to collecting data via handwritten scripts."),(0,r.kt)("h4",{id:"user-scenarios"},"User scenarios"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"IoT sensor data:")," Data transferred based on protocols such as MQTT, ModBus, OPC-UA, and Kafka."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"DevOps framework data:")," Operational metrics from platforms or frameworks such as GitHub, Kubernetes, CloudWatch, Prometheus, etc."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"System telemetry data:")," System telemetry metrics such as iptables, Netstat, NGINX and HAProxy")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Plug-in System")),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"Input:")," Collects metrics data from systems, services, or third-party APIs."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"Process:")," Process and trim the metrics data before sending them to maintain data cleanliness."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"Aggregate:")," Generate aggregated metrics, such as average, minimum, and maximum values of metric data."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"Output:")," Writing data to a data store, service or message queue such as InfluxDB, Graphite, OpenTSDB, Datadog, Kafka, MQTT, NSQ, etc.")),(0,r.kt)("p",null,"In the following, we will describe how to install and configure Telegraf for collecting system metrics data and storing it in CnosDB."),(0,r.kt)("h3",{id:"telegraf-deployment"},(0,r.kt)("strong",{parentName:"h3"},"Telegraf Deployment")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("h4",{parentName:"li",id:"download"},"Download"),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("a",{parentName:"p",href:"https://portal.influxdata.com/downloads/"},"Official Download Link"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Installation")),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("a",{parentName:"p",href:"https://docs.influxdata.com/telegraf/v1.23/install/"},"Offical Installation Tutorial(v1.23)"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Start")),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("a",{parentName:"p",href:"https://docs.influxdata.com/telegraf/v1.23/get_started/"},"Offical Basic Tutorisl(v1.23)")))),(0,r.kt)("h3",{id:"telegraf-configuration"},(0,r.kt)("strong",{parentName:"h3"},"Telegraf Configuration")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("h4",{parentName:"li",id:"generate-configuration-files-manually"},"Generate configuration files manually"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"telegraf --sample-config > telegraf.conf\n"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("h4",{parentName:"li",id:"default-configuration-file-path"},"Default configuration file path"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"macOS ",(0,r.kt)("strong",{parentName:"li"},"Homebrew"),": ",(0,r.kt)("inlineCode",{parentName:"li"},"/usr/local/etc/telegraf.conf")),(0,r.kt)("li",{parentName:"ul"},"Linux debian and RPM packages: ",(0,r.kt)("inlineCode",{parentName:"li"},"/etc/telegraf/telegraf.conf")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("h4",{parentName:"li",id:"use-a-text-editor-such-as-vim-to-modify-the-configuration-file"},"Use a text editor such as ",(0,r.kt)("inlineCode",{parentName:"h4"},"vim")," to modify the configuration file."),(0,r.kt)("p",{parentName:"li"},"In order to output the metrics data to CnosDB, we need to configure Telegraf's output plug-in ",(0,r.kt)("inlineCode",{parentName:"p"},"http")," to output line protocol data to the write interface of CnosDB."),(0,r.kt)("p",{parentName:"li"},"Find [","[",(0,r.kt)("inlineCode",{parentName:"p"},"outputs.http"),"]","] in the configuration file and modify it as follows:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-toml"},'[[outputs.http]]\nurl = "http://CnosDB_Addr:CnosDB_Port/api/v1/write?db=cnos"\ntimeout = "5s"\nmethod = "POST"\nusername = "username"\npassword = "password"\ndata_format = "influx"\nuse_batch_format = true\ncontent_encoding = "identity"\nidle_conn_timeout = 10\n')),(0,r.kt)("p",{parentName:"li"},"In the above configuration, there are some texts needed to be replaced:"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"CnosDB_address")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"CnosDB_port")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"username")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"password"))),(0,r.kt)("p",{parentName:"li"},"as, for example:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-toml"},'[[outputs.http]]\nurl = "http://host.docker.internal:31007/api/v1/write?db=cnos"\ntimeout = "5s"\nmethod = "POST"\nusername = "admin"\npassword = "admin"\ndata_format = "influx"\nuse_batch_format = true\ncontent_encoding = "identity"\nidle_conn_timeout = 10\n')),(0,r.kt)("p",{parentName:"li"},"Next, start the Telegraf service and provide the configuration file path:"),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"macOS Homebrew")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"telegraf --config telegraf.conf\n")),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Linux (sysvinit and upstart installations)")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"sudo service telegraf start\n")),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Linux (systemd installations)")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"systemctl start telegraf\n")),(0,r.kt)("p",{parentName:"li"},"Next, use the CnosDB query interface to view the data to verify that Telegraf is running correctly:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"curl -XPOST -H 'ACCEPT: application/json' -H \"AUTHORIZATION: Basic $(echo '\u7528\u6237\u540d:\u5bc6\u7801'|base64)\" 'http://CnosDB\u5730\u5740:CnosDB\u7aef\u53e3/api/v1/sql?db=cnos' -d 'SELECT * from cpu limit 1'\n")),(0,r.kt)("p",{parentName:"li"},"In the above configuration, there are some texts needed to be replaced:"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"CnosDB_address")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"CnosDB_port")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"username")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"password"))),(0,r.kt)("p",{parentName:"li"},"as, for example:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"> curl -XPOST -H 'ACCEPT: application/json' -H \"AUTHORIZATION: Basic $(echo 'admin:admin'|base64)\" 'http://127.0.0.1:31007/api/v1/sql?db=cnos' -d 'SELECT * from cpu limit 1'\n")),(0,r.kt)("p",{parentName:"li"},"Under correct configuration, you will obtain the following results:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-json"},'[\n{\n"cpu": "cpu0",\n"host": "_HOST",\n"time": "2022-10-10 10:10:10",\n"usage_guest": 0.0,\n"usage_guest_nice": 0.0,\n"usage_idle": 99.49899799596298,\n"usage_iowait": 0.10020040080156893,\n"usage_irq": 0.0,\n"usage_nice": 0.0,\n"usage_softirq": 0.10020040080156893,\n"usage_steal": 0.0,\n"usage_system": 0.10020040080155113,\n"usage_user": 0.20040080160317345\n}\n]\n')))),(0,r.kt)("h2",{id:"cnos-telegraf"},"Cnos-Telegraf"),(0,r.kt)("p",null,"CnosDB-Telegraf is based on Telegraf (re1.25, commit 86cd0c0c2), with some added features and plugins."),(0,r.kt)("h3",{id:"description-of-the-changes-compared-to-telegraf"},(0,r.kt)("strong",{parentName:"h3"},"Description of the changes compared to Telegraf")),(0,r.kt)("h4",{id:"parser-plugin"},"Parser Plugin"),(0,r.kt)("p",null,"Add Parser plug-ins OpenTSDB and OpenTSDB-Telnet to collect write requests from OpenTSDB."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"OpenTSDB")),(0,r.kt)("p",{parentName:"li"},"By using the Input plugin http_listener_v2 and configuring the ",(0,r.kt)("inlineCode",{parentName:"p"},"data_format"),' to "',(0,r.kt)("inlineCode",{parentName:"p"},"opentsdb"),'", you will be able to parse write requests in OpenTSDB format.'),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-toml"},'[[inputs.http_listener_v2]]\nservice_address = ":8080"\npaths = ["/api/put"]\nmethods = ["POST", "PUT"]\ndata_format = "opentsdb"\n'))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"OpenTSDB-Telnet")),(0,r.kt)("p",{parentName:"li"},"By using the Input plugin socket_listener and configuring the ",(0,r.kt)("inlineCode",{parentName:"p"},"data_format"),' to "',(0,r.kt)("inlineCode",{parentName:"p"},"opentsdbtelnet"),'", you will be able to parse write requests in OpenTSDB-Telnet format.'),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-toml"},'[[inputs.socket_listener]]\nservice_address = "tcp://:8081"\ndata_format = "opentsdbtelnet"\n')))),(0,r.kt)("h4",{id:"output-plugin"},"Output Plugin"),(0,r.kt)("p",null,"Add Output plugin CnosDB for exporting metrics to CnosDB."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-toml"},'[[outputs.cnosdb]]\nurl = "localhost:31006"\nuser = "user"\npassword = "pass"\ndatabase = "telegraf"\n')),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Configuration introduction"))),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"th"},"Parameters")),(0,r.kt)("th",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"th"},"Description")))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"url"),(0,r.kt)("td",{parentName:"tr",align:null},"CnosDB GRpc service address")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"user"),(0,r.kt)("td",{parentName:"tr",align:null},"User Name")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"password"),(0,r.kt)("td",{parentName:"tr",align:null},"Password")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"database"),(0,r.kt)("td",{parentName:"tr",align:null},"CnosDB database")))),(0,r.kt)("h4",{id:"input-plugin"},"Input Plugin"),(0,r.kt)("p",null,"Add the configuration parameter high_priority_io to enable end-to-end mode."),(0,r.kt)("p",null,"When set to true, the written data will be sent to the Output plug-in immediately and the return value will be determined based on the Output plug-in's return parameters."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-toml"},'[[inputs.http_listener_v2]]\nservice_address = ":8080"\npaths = ["/api/put"]\nmethods = ["POST", "PUT"]\ndata_format = "opentsdb"\nhigh_priority_io = true\n')),(0,r.kt)("p",null,"The above configuration adds the ",(0,r.kt)("inlineCode",{parentName:"p"},"high_priority_io = true")," configuration compared to the configuration in the ",(0,r.kt)("a",{parentName:"p",href:"#output-plugin"},"Output Plugin")," section."),(0,r.kt)("h3",{id:"build"},(0,r.kt)("strong",{parentName:"h3"},"Build")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("h4",{parentName:"li",id:"install-go-118-1180-version-recommended"},(0,r.kt)("a",{parentName:"h4",href:"https://golang.org/doc/install"},"Install Go")," >=1.18 (1.18.0 version recommended)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("h4",{parentName:"li",id:"clone-the-repository-from-github"},"Clone the repository from Github:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"git clone https://github.com/cnosdb/cnos-telegraf.git\n"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("h4",{parentName:"li",id:"execute-make-build-in-the-repository-directory"},"execute ",(0,r.kt)("inlineCode",{parentName:"h4"},"make build")," in the repository directory"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"cd cnos-telegraf\nmake build\n")))),(0,r.kt)("h3",{id:"start"},(0,r.kt)("strong",{parentName:"h3"},"Start")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("h4",{parentName:"li",id:"execute-the-following-command-to-view-the-use-case"},"Execute the following command to view the use case:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"telegraf --help\n"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("h4",{parentName:"li",id:"generate-a-standard-telegraf-configuration-file"},(0,r.kt)("strong",{parentName:"h4"},"Generate a standard telegraf configuration file")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"telegraf config > telegraf.conf\n"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("h4",{parentName:"li",id:"generate-a-telegraf-configuration-file-that-contains-only-the-cpu-metrics-collection--influxdb-output-plugins"},(0,r.kt)("strong",{parentName:"h4"},"Generate a telegraf configuration file that contains only the cpu metrics collection & influxdb output plugins")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"telegraf config --section-filter agent:inputs:outputs --input-filter cpu --output-filter influxdb\n"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("h4",{parentName:"li",id:"run-telegraf-but-output-the-capture-metrics-to-the-standard-output"},(0,r.kt)("strong",{parentName:"h4"},"Run telegraf but output the capture metrics to the standard output")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"telegraf --config telegraf.conf --test\n"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("h4",{parentName:"li",id:"run-telegraf-and-manage-the-loaded-plugins-through-the-configuration-file"},(0,r.kt)("strong",{parentName:"h4"},"Run telegraf and manage the loaded plugins through the configuration file")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"telegraf --config telegraf.conf\n"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("h4",{parentName:"li",id:"run-telegraf-load-only-the-cpu--memory-metrics-collection-and-the-influxdb-output-plugin"},(0,r.kt)("strong",{parentName:"h4"},"Run telegraf, load only the cpu & memory metrics collection, and the influxdb output plugin")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"telegraf --config telegraf.conf --input-filter cpu:mem --output-filter influxdb\n")))),(0,r.kt)("h2",{id:"grafana"},"Grafana"),(0,r.kt)("h3",{id:"introduction"},"Introduction"),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(4079).Z,width:"1749",height:"1001"})),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/grafana/grafana"},"Grafana")," is an open source data visualization tool that easily converts any conforming data into visual charts and comes with an alerting feature that notifies you when metric data reaches a threshold. Grafana supports multiple data sources by default and can also be extended through a plugin system."),(0,r.kt)("p",null,"We will describe the process of getting CnosDB data through Grafana to present a dashboard."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-mermaid"},"graph LR\nsubgraph s1[Server]\ntg1[Telegraf]\nend\ntg1--metrics data--\x3eCnosDB\nCnosDB--data frame--\x3eGrafana\n")),(0,r.kt)("h3",{id:"grafana-deployment"},"Grafana Deployment"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://grafana.com/docs/grafana/latest/setup-grafana/installation/"},"Official Installation Tutorial")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://grafana.com/docs/grafana/latest/setup-grafana/configure-grafana/"},"Official profile description")),(0,r.kt)("h3",{id:"grafana-configuration"},"Grafana Configuration"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("h4",{parentName:"li",id:"connect-cnosdb"},(0,r.kt)("strong",{parentName:"h4"},"Connect CnosDB")),(0,r.kt)("p",{parentName:"li"},"Type ",(0,r.kt)("inlineCode",{parentName:"p"},"http://localhost:3000"),"\uff0cand the Grafana login screen will show up if running correctly. The original username and password are both admin."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{src:a(4205).Z,width:"1431",height:"902"})),(0,r.kt)("p",{parentName:"li"},"You will be asked to set a new password when you first login. The main Grafana interface shows up after this."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{src:a(7819).Z,width:"1431",height:"902"})),(0,r.kt)("p",{parentName:"li"},"Grafana provides a common data interface that allows us to read data from the CnosDB database via the CnosDB data source plugin. Firstly, we shall go to the data source configuration screen."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{src:a(2177).Z,width:"1431",height:"902"})),(0,r.kt)("p",{parentName:"li"},"Then cilck the ","[",(0,r.kt)("inlineCode",{parentName:"p"},"Add data source"),"]"," button."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{src:a(3827).Z,width:"1363",height:"271"})),(0,r.kt)("p",{parentName:"li"},"Search for CnosDB and click to enter the configuration screen."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{src:a(2558).Z,width:"1431",height:"902"})),(0,r.kt)("p",{parentName:"li"},"In the configuration screen, enter the address of CnosDB and username, and then click the ","[",(0,r.kt)("inlineCode",{parentName:"p"},"Save & test"),"]"," button."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{src:a(2282).Z,width:"1431",height:"902"})),(0,r.kt)("p",{parentName:"li"},"You shall see ","[",(0,r.kt)("inlineCode",{parentName:"p"},"Data source is working"),"]"," under correct configuration, indicating that Grafana has access to CnosDB data."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{src:a(3118).Z,width:"485",height:"279"}))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("h4",{parentName:"li",id:"configure-dashboard"},(0,r.kt)("strong",{parentName:"h4"},"Configure Dashboard")),(0,r.kt)("p",{parentName:"li"},"Grafana can configure dashboards via a graphical interface. The configured dashboards can be exported via JSON formatted data or imported as JSON formatted dashboard data."),(0,r.kt)("p",{parentName:"li"},"We shall import a piece of dashboard data."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{src:a(7186).Z,width:"1431",height:"902"})),(0,r.kt)("p",{parentName:"li"},"Copy the ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/cnosdb/docs/blob/main/assets/grafana_dashboard.json"},"JSON")," to ","[",(0,r.kt)("inlineCode",{parentName:"p"},"import via panel json"),"]",", and then click the ","[",(0,r.kt)("inlineCode",{parentName:"p"},"load"),"]"," button."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{src:a(2604).Z,width:"1431",height:"902"})),(0,r.kt)("p",{parentName:"li"},"Next, select the CnosDB data source we just configured, and click the ","[",(0,r.kt)("inlineCode",{parentName:"p"},"import"),"]"," button."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{src:a(8756).Z,width:"696",height:"629"})),(0,r.kt)("p",{parentName:"li"},"We've then created a dashboard."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{src:a(8476).Z,width:"1431",height:"902"})))),(0,r.kt)("h2",{id:"prometheus"},"Prometheus"),(0,r.kt)("h3",{id:"introduction-1"},"Introduction"),(0,r.kt)("p",null,"Prometheus is a cloud-native monitoring software that enables data acquisition and monitoring for a wide range of software and systems."),(0,r.kt)("p",null,"This article describes how to configure CnosDB as a Prometheus terminal via the Prometheus Remote Read/ Write interface."),(0,r.kt)("h3",{id:"precondition"},"Precondition"),(0,r.kt)("p",null,"Start CnosDB service, get the address of  CnosDB service."),(0,r.kt)("h3",{id:"remote-write"},"Remote Write"),(0,r.kt)("p",null,"CnosDB supports the Remote Write protocol of Prometheus. To ingest data to the logging service, simply enable the Remote Write functionality in Prometheus, as shown below."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Operation flow")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Edit configuration file")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"# remote_write cnosdb\nremote_write:\n- url: \"http://{db_url}/api/v1/prom/write?db={db_name}\"\n  basic_auth:\n  username: 'root'\n  password: ''\n")),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Parameter")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre"},"db_url: Http Server address of CnosDB, such as 127.0.0.1:31001\ndb_name: Remote Write database name\nusername: CnosDB username\npassword: CnosDB user's password\n")))),(0,r.kt)("p",null,"You can get the all configuration of Prometheus Remote Write via ",(0,r.kt)("a",{parentName:"p",href:"https://prometheus.io/docs/prometheus/latest/configuration/configuration/?spm=a2c4g.11186623.0.0.231f780eoLUxCY#remote_write"},"Prometheus"),"."),(0,r.kt)("h3",{id:"remote-read"},"Remote Read"),(0,r.kt)("p",null,"CnosDB supports Remote Read protocol of Prometheus. To ingest data to the logging service, simply enable the Remote Read functionality in Prometheus, as shown below."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Operation flow")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Edit configure file")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"# remote_read cnosdb\nremote_read:\n- url: \"http://{db_url}/api/v1/prom/read?db={db_name}\"\n  basic_auth:\n  username: 'root'\n  password: ''\n")),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Parameter")),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Parameter")),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre"},"db_url: Http Server address of CnosDB, such as 127.0.0.1:31001\ndb_name: Remote Write database name\nusername: CnosDB username\npassword: CnosDB user's password\n")))),(0,r.kt)("p",null,"You can get the all configuration of Prometheus Remote Read via ",(0,r.kt)("a",{parentName:"p",href:"https://prometheus.io/docs/prometheus/latest/configuration/configuration/?spm=a2c4g.11186623.0.0.231f780eoLUxCY#remote_read"},"Prometheus"),"."),(0,r.kt)("h2",{id:"tensorflow"},"TensorFlow"),(0,r.kt)("h3",{id:"use-cnosdb-and-tensorflow-for-time-series-prediction"},"Use CnosDB and TensorFlow for time series prediction"),(0,r.kt)("h3",{id:"from-three-body-motion-to-sunspot-change-prediction"},"From three-body motion to Sunspot Change prediction"),(0,r.kt)("h4",{id:"introduction-2"},"Introduction"),(0,r.kt)("p",null,"Sunspots are solar activity that occurs in the photosphere of the sun and usually appear in groups. Predicting sunspot changes is one of the most active areas of space weather research."),(0,r.kt)("p",null,"Sunspot observations last for a long time. Long-term data accumulation is conducive to mining the law of sunspot variation. The long-term observation shows that the sunspot number and area change show obvious periodicity, and the period is irregular, roughly ranging from 9 to 13 years, the average period is about 11 years, and the peak value of the sunspot number and area change is not constant."),(0,r.kt)("p",null,"The latest data show that the number and area of sunspots have declined significantly in recent years."),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(9023).Z,width:"2048",height:"1536"})),(0,r.kt)("p",null,"Since the intensity of sunspot activity has a profound impact on Earth, it is particularly important to detect sunspot activity. Physics-based models, such as dynamical models, and statistical models, such as autoregressive moving averages, have been widely used to detect sunspot activity.\nIn order to capture the nonlinear relationship in sunspot time series more efficiently, machine learning methods are introduced."),(0,r.kt)("p",null,"It is worth mentioning that neural networks in machine learning are better at mining nonlinear relationships in data."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"}," Therefore, this article will introduce how to use the time series database 'CnosDB' to store the sunspot change data and further use TensorFlow to implement the '1DConv+LSTM' network to predict the sunspot number change. ")),(0,r.kt)("h4",{id:"introduction-to-the-sunspot-change-observation-dataset"},"Introduction to the Sunspot Change Observation dataset"),(0,r.kt)("p",null,"The sunspot dataset used in this paper was released by the SILSO website version 2.0. (WDC-SILSO, Royal Observatory of Belgium, Brussels,",(0,r.kt)("a",{parentName:"p",href:"http://sidc.be/silso/datafiles"},"http://sidc.be/silso/datafiles"),")"),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(9539).Z,width:"998",height:"1032"})),(0,r.kt)("p",null,"We mainly analyze and explore the changes of the monthly mean sunspot number (MSSN) from 1749 to 2023."),(0,r.kt)("h3",{id:"import-data-to-cnosdb"},"Import Data to CnosDB"),(0,r.kt)("p",null,"Download MSSN data ",(0,r.kt)("inlineCode",{parentName:"p"},"SN_m_tot_V2.0.csv"),"\uff08",(0,r.kt)("a",{parentName:"p",href:"https://www.sidc.be/silso/infosnmtot%EF%BC%89"},"https://www.sidc.be/silso/infosnmtot\uff09"),"."),(0,r.kt)("p",null,"Here is the official description of the CSV file:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Filename: SN_m_tot_V2.0.csv\nFormat: Comma Separated values (adapted for import in spreadsheets)\nThe separator is the semicolon ';'.\n\nContents:\nColumn 1-2: Gregorian calendar date\n- Year\n- Month\nColumn 3: Date in fraction of year.\nColumn 4: Monthly mean total sunspot number.\nColumn 5: Monthly mean standard deviation of the input sunspot numbers.\nColumn 6: Number of observations used to compute the monthly mean total sunspot number.\nColumn 7: Definitive/provisional marker. '1' indicates that the value is definitive. '0' indicates that the value is still provisional.\n")),(0,r.kt)("p",null,"We use ",(0,r.kt)("inlineCode",{parentName:"p"},"pandas")," for file loading and previewing."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import pandas as pd\n\ndf = pd.read_csv("SN_m_tot_V2.0.csv", sep=";", header=None)\ndf.columns = ["year", "month", "date_fraction", "mssn", "standard_deviation", "observations", "marker"]\n\n# convert year and month to strings\ndf["year"] = df["year"].astype(str)\ndf["month"] = df["month"].astype(str)\n\n# concatenate year and month\ndf["date"] = df["year"] + "-" + df["month"]\n\ndf.head()\n')),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(8433).Z,width:"1226",height:"356"})),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import matplotlib.pyplot as plt \n\ndf["Date"] = pd.to_datetime(df["date"], format="%Y-%m")\nplt.plot(df["Date"], df["mssn"])\nplt.xlabel("Date")\nplt.ylabel("MSSN")\nplt.title("Sunspot Activity Over Time")\nplt.show()\n')),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(7069).Z,width:"1426",height:"880"})),(0,r.kt)("h4",{id:"use-tsdb-cnosdb-to-store-mssn-data"},"Use TSDB CnosDB to store MSSN data"),(0,r.kt)("p",null,"CnosDB\uff08An Open Source Distributed Time Series Database with high performance, high compression ratio and high usability.\uff09"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Official Website: ",(0,r.kt)("a",{parentName:"li",href:"http://www.cnosdb.com"},"http://www.cnosdb.com")),(0,r.kt)("li",{parentName:"ul"},"Github Repo: ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/cnosdb/cnosdb"},"https://github.com/cnosdb/cnosdb"))),(0,r.kt)("p",null,"\uff08Notice\uff1aWe suppose the you have the ability to deploy and use CnosDB. You can get more information through ",(0,r.kt)("a",{parentName:"p",href:"https://docs.cnosdb.com/%EF%BC%89"},"https://docs.cnosdb.com/\uff09")),(0,r.kt)("p",null,"Use Docker to start CnosDB service in command line, enter the container and use the ",(0,r.kt)("a",{parentName:"p",href:"/docs/reference/tools"},"CnosDB CLI")," to use CnosDB\uff1a"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-SHELL"},'(base) root@ecs-django-dev:~# docker run --restart=always --name cnosdb -d --env cpu=2 --env memory=4 -p 31007:31007 cnosdb/cnosdb:v2.0.2.1-beta\n\n(base) root@ecs-django-dev:~# docker exec -it cnosdb sh sh\n# cnosdb-cli\nCnosDB CLI v2.0.0\nInput arguments: Args { host: "0.0.0.0", port: 31007, user: "cnosdb", password: None, database: "public", target_partitions: None, data_path: None, file: [], rc: None, format: Table, quiet: false }\n')),(0,r.kt)("p",null,"To simplify the analysis, we only need to store the observation time and the number of sunspots in the dataset. Therefore, we concatenate the year (Col 0) and month (Col 1) as the observation time (date, string type), and the monthly mean sunspot number (Col 3) can be stored directly without processing."),(0,r.kt)("p",null,"We can create a 'sunspot' table in CnosDB CLI using SQL to store the MSSN dataset."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-SQL"},"public \u276f CREATE TABLE sunspot (\n    date STRING,\n    mssn DOUBLE,\n);\nQuery took 0.002 seconds.\n\npublic \u276f SHOW TABLES;\n+---------+\n| Table   |\n+---------+\n| sunspot |\n+---------+\nQuery took 0.001 seconds.\n\npublic \u276f SELECT * FROM sunspot;\n+------+------+------+\n| time | date | mssn |\n+------+------+------+\n+------+------+------+\nQuery took 0.002 seconds.\n")),(0,r.kt)("h4",{id:"use-cnosdb-python-connector-to-connect-and-use-cnosdb-database"},"Use CnosDB Python Connector to Connect and Use CnosDB Database"),(0,r.kt)("p",null,"Github Repo: ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/cnosdb/cnosdb-client-python"},"https://github.com/cnosdb/cnosdb-client-python")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# install Python Connector\npip install -U cnos-connector\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from cnosdb_connector import connect\n\nconn = connect(url="http://127.0.0.1:31001/", user="root", password="")\ncursor = conn.cursor()\n')),(0,r.kt)("p",null,"If you are not familiar wit ",(0,r.kt)("a",{parentName:"p",href:"/docs/reference/tools"},"CnosDB CLI")," \uff0cWe can use Python Connector to create a data table."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'\n# create tf_demo database\nconn.create_database("tf_demo")\n# \u4f7f\u7528 tf_demo database\nconn.switch_database("tf_demo")\nprint(conn.list_database())\n\ncursor.execute("CREATE TABLE sunspot (date STRING, mssn DOUBLE,);")\nprint(conn.list_table())\n')),(0,r.kt)("p",null,"Outputs are as follows, the default database of CnosDB included."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"[{'Database': 'tf_demo'}, {'Database': 'usage_schema'}, {'Database': 'public'}]\n[{'Table': 'sunspot'}]\n")),(0,r.kt)("p",null,"Write the dataframe of pandas to CnosDB."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"### df is the dataframe of pandas, \"sunspot\" is the table name of CnosDB, ['date', 'mssn'] are the name of columns to be written.\n### If you write a column that does not contain a time column, it will be automatically generated based on the current time\nconn.write_dataframe(df, \"sunspot\", ['date', 'mssn'])\n")),(0,r.kt)("h3",{id:"cnodb-reads-the-data-and-uses-tensorflow-to-reproduce-the-1dconvlstm-network-to-predict-sunspot-changes"},"CnoDB reads the data and uses TensorFlow to reproduce the 1DConv+LSTM network to predict sunspot changes"),(0,r.kt)("p",null,"References\uff1a",(0,r.kt)("a",{parentName:"p",href:"http://journal.ucas.ac.cn/CN/10.7523/j.ucas.2021.0068"},'\u7a0b\u672f, \u77f3\u8000\u9716, and \u5f20\u6000. "\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u592a\u9633\u9ed1\u5b50\u53d8\u5316." (2022).\n')),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(3267).Z,width:"1844",height:"600"})),(0,r.kt)("h4",{id:"use-cnosdb-to-read-data"},"Use CnosDB to Read Data"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'df = pd.read_sql("select * from sunspot;", conn)\n\nprint(df.head())\n')),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(6424).Z,width:"870",height:"240"})),(0,r.kt)("h4",{id:"divide-the-data-into-training-set-and-test-set"},"Divide the data into training set and test set"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import numpy as np\n# Convert the data values to numpy for better and faster processing\ntime_index = np.array(df['date'])\ndata = np.array(df['mssn'])   \n\n# ratio to split the data\nSPLIT_RATIO = 0.8\n\n# Dividing into train-test split\nsplit_index = int(SPLIT_RATIO * data.shape[0])   \n\n# Train-Test Split\ntrain_data = data[:split_index]\ntrain_time = time_index[:split_index]  \ntest_data = data[split_index:]\ntest_time = time_index[split_index:]\n")),(0,r.kt)("h4",{id:"use-the-sliding-window-method-to-construct-the-training-data"},"Use the Sliding Window Method to Construct the Training Data"),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(2317).Z,width:"758",height:"322"})),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import tensorflow as tf\n\n## required parameters\nWINDOW_SIZE = 60\nBATCH_SIZE = 32\nSHUFFLE_BUFFER = 1000\n\n## function to create the input features\ndef ts_data_generator(data, window_size, batch_size, shuffle_buffer):\n    '''\n    Utility function for time series data generation in batches\n    '''\n    ts_data = tf.data.Dataset.from_tensor_slices(data)\n    ts_data = ts_data.window(window_size + 1, shift=1, drop_remainder=True)\n    ts_data = ts_data.flat_map(lambda window: window.batch(window_size + 1))\n    ts_data = ts_data.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n    ts_data = ts_data.batch(batch_size).prefetch(1)\n    return ts_data# Expanding data into tensors\n\n\n# Expanding data into tensors\ntensor_train_data = tf.expand_dims(train_data, axis=-1)\ntensor_test_data = tf.expand_dims(test_data, axis=-1)\n\n## generate input and output features for training and testing set\ntensor_train_dataset = ts_data_generator(tensor_train_data, WINDOW_SIZE, BATCH_SIZE, SHUFFLE_BUFFER)\ntensor_test_dataset = ts_data_generator(tensor_test_data, WINDOW_SIZE, BATCH_SIZE, SHUFFLE_BUFFER)\n")),(0,r.kt)("h4",{id:"use-the-tfkeras-module-to-define-the-1dconvlstm-neural-network-model"},"Use the tf.keras module to Define the 1DConv+LSTM Neural Network Model"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'model = tf.keras.models.Sequential([\n                            tf.keras.layers.Conv1D(filters=128, kernel_size=3, strides=1, input_shape=[None, 1]),\n                            tf.keras.layers.MaxPool1D(pool_size=2, strides=1),\n                            tf.keras.layers.LSTM(128, return_sequences=True),\n                            tf.keras.layers.LSTM(64, return_sequences=True),  \n                            tf.keras.layers.Dense(132, activation="relu"),  \n                            tf.keras.layers.Dense(1)])\n\n\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'## compile neural network model\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\nmodel.compile(loss="mse",\n            optimizer=optimizer,\n            metrics=["mae"])\n## training neural network model\nhistory = model.fit(tensor_train_dataset, epochs=20, validation_data=tensor_test_dataset)\n')),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(8180).Z,width:"1061",height:"843"})),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n")),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(8529).Z,width:"1386",height:"924"})),(0,r.kt)("h4",{id:"predict-the-mssn-using-the-trained-model"},"Predict the MSSN using the trained model"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"def model_forecast(model, data, window_size):\n    ds = tf.data.Dataset.from_tensor_slices(data)\n    ds = ds.window(window_size, shift=1, drop_remainder=True)\n    ds = ds.flat_map(lambda w: w.batch(window_size))\n    ds = ds.batch(32).prefetch(1)\n    forecast = model.predict(ds)\n    return forecast\n\nrnn_forecast = model_forecast(model, data[..., np.newaxis], WINDOW_SIZE)\nrnn_forecast = rnn_forecast[split_index - WINDOW_SIZE:-1, -1, 0]\n# Overall Error\nerror = tf.keras.metrics.mean_absolute_error(test_data, rnn_forecast).numpy()\nprint(error)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"101/101 [==============================] - 2s 18ms/step\n24.676455\n")),(0,r.kt)("h4",{id:"visualization-of-the-results-compared-to-the-ground-truth"},"Visualization of the results compared to the ground truth"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"plt.plot(test_data)\nplt.plot(rnn_forecast)\nplt.title('MSSN Forecast')\nplt.ylabel('MSSN')\nplt.xlabel('Month')\nplt.legend(['Ground Truth', 'Predictions'], loc='upper right')\nplt.show()\n")),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(2297).Z,width:"1302",height:"910"})))}c.isMDXComponent=!0},9023:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/Hathaway_Cycle_24_Prediction-d77b95cc5f8a4cf32d9501448e321319.png"},3267:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/MSSN-4c8e35a7961578b82069dc7cbdf848a6.png"},6424:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/cnosdb_dataframe-2220cdd717338d9a09abbfbdb305c8a6.png"},8476:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/grafana_dashboard_1-9e25a26ca151ccea10944159af148792.png"},2604:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/grafana_import_dashboard_1-5df41f70129c0a8078489614b580554d.png"},8756:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/grafana_import_dashboard_2-b8ef3d8fe83ed98f38be162cf9afb71a.png"},4205:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/grafana_login_page-21bd757142f576cd478ddcf05e029e74.png"},7819:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/grafana_main_page_1-a257c60ca81fcb5099c1643fec6a787d.png"},2177:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/grafana_main_page_2-fccceedf1db49d8c78ae341af73e5831.png"},7186:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/grafana_main_page_3-0eb8daac5f8acf6dd7bacc882dacbfef.png"},4079:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/grafana_overview-3120b61f340df4d8df75f2b3c6a9ad0b.webp"},2558:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/grafana_setting_add_data_source_1-d5ccbade9089f350471f96132318149e.png"},2282:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/grafana_setting_add_data_source_2-7e844ec07cf643734cbb9491acab002c.png"},3118:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/grafana_setting_add_data_source_3-943e0295d687c4cba6ce43f1e008a924.png"},3827:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/grafana_setting_add_data_source_button-3562d2a38196d9db0597edba00566d66.png"},8529:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/model_resault-415e9d52b8ea63047d39eb70fa9b57e3.png"},2297:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/model_resault_compare-99874a1b6e03d2b0343cdd446c66e84d.png"},8433:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/pandas_dataframe-2af7043e972e584665eea4b169e02494.png"},7069:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/plt_show-3927372e49e3033f475ade409bead84d.png"},2317:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/sliding_window_method-1e703cd0da620b31c47328f97746d0d8.png"},9539:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/sunspot_dataset-c86ab506c02247aa534e01eca7f0561a.png"},8180:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tensorflow-c62ff659c87ce124f1d6ac9ebf346567.png"}}]);